# Importación de librerías y cargar base de datos
"""

# Commented out IPython magic to ensure Python compatibility.
#Preparamos complementos, librerías y bases disponibles
import warnings

warnings.filterwarnings("ignore")

!pip install pandas numpy sweetviz seaborn matplotlib scikit-learn
!pip install kneed

#Instalación de complemento
!pip install sweetviz

#importar librerias
#importar librerias
import pandas as pd
import numpy as np
import sweetviz as sv
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import kneed as kd

from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import ShuffleSplit
from sklearn import datasets
import numpy as np
import pandas as pd
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from kneed import KneeLocator
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_score
# %matplotlib inline

#Cargamos la base alojada en GitHub
BDD = pd.read_csv("https://raw.githubusercontent.com/veronica1908/T2_APRENDIZAJE_NO_SUPERVISADO/main/BASE_SIN_PROCESAR.csv", sep = ',')

#Verificamos la visualización
BDD.head()

"""# Preprocesamiento de los datos

##Información y estado de la base de datos
"""

#Verificamos las dimensiones de la base
BDD.shape

# Vemos información de las variables, como datos NO nulos y tipo de dato
BDD.info()

# Empezamos eliminando la variable N° que funciona como un identificador de losd atos de la base y que no aporta para el ejercicio.
BDD.drop(['N°',], axis=1, inplace=True)

# Vemos la cantidad de datos nulos por variable
BDD.isnull().sum()

#Existen muchos datos nulos y como las dimensiones de la base son considerablemente grandes, se eliminarán las filas cuyos datos nulos pertenezcan a variables núméricas importantes y para las filas de texto, se agregará "Sin información"

"""##Ajuste de las variables de la base de datos"""

#Vamos a verificar cada columna para tomar decisiones en el ajuste de datos de cada una de ellas
#Como la columna "Departamento defunción" no tiene datos nulos, verificamos entonces sus categorías en orden alfabético para detectar posibles errores en el ingreso de datos
sorted(BDD['Departamento defunción'].unique())
#Verificamos la cantidad de datos por departamento
BDD['Departamento defunción'].value_counts()

#Como la gran mayoría de datos pertenecen al departamento del VALLE DEL CAUCA, nos centraremos en estos datos y eliminaremos los que pertenecen a otros departamentos
dep_elim = ['CUNDINAMARCA','SANTA FE DE BOGOTÁ','RISARALDA','TOLIMA','NARIÑO','CASANARE','GUAVIARE','QUINDIO']
BDD = BDD[~BDD['Departamento defunción'].isin(dep_elim)]

#Como la columna "Municipio defunción" tampoco tiene datos nulos, verificamos también sus categorías
sorted(BDD['Municipio defunción'].unique())
#se observa que pueden combinarse las categorías "CALIMA' y 'CALIMA (DARIEN)'

#Se combinan las categorías "CALIMA' y 'CALIMA (DARIEN)' y BUGA con GUADALAJARA DE BUGA
BDD['Municipio defunción'] = BDD['Municipio defunción'].replace({'CALIMA (DARIEN)': 'CALIMA'})
BDD['Municipio defunción'] = BDD['Municipio defunción'].replace({'BUGA': 'GUADALAJARA DE BUGA'})
#Verificamos
sorted(BDD['Municipio defunción'].unique())

#Columna "Área defunción" tiene 3 datos nulos, los llenamos con el texto "SIN INFORMACIÓN" y verificamos también sus categorías
#Agregamos información a celdas vacías
BDD['Área defunción'].fillna('SIN INFORMACIÓN', inplace=True)
#Verificamos categorías
sorted(BDD['Área defunción'].unique())

#Unificamos las categorías: "CENTRO POBLADO (Inspección,\r\ncorregimiento o caserío)" y 'CENTRO POBLADO (INSPECCIÓN, CORREGIMIENTO O CASERÍO)' como "CENTRO POBLADO"
BDD['Área defunción'] = BDD['Área defunción'].replace({'"CENTRO POBLADO (Inspección,\r\ncorregimiento o caserío)"': 'CENTRO POBLADO', 'CENTRO POBLADO (INSPECCIÓN, CORREGIMIENTO O CASERÍO)':'CENTRO POBLADO'})
#Verificamos ajustes
sorted(BDD['Área defunción'].unique())

#Columna "Sitio defunción" no tiene datos nulos, verificamos categorías
sorted(BDD['Sitio defunción'].unique())
#No hay ajustes para esta variable

#Columna "Sitio defunción" no tiene datos nulos, verificamos categorías
sorted(BDD['Sitio defunción'].unique())
#No hay ajustes para esta variable

#Columna "Otro sitio de defunción" tiene 5254 nulos. Esta columna existe solo como complemento para la categoría "OTRO" de la variable "Sitio defunción",
#Por lo tanto, se reemplazará los datos nulos con el texto "NA" (no aplica), para las filas del resto de las categorías diferentes a "OTRO" que aparecen como nulos

#Agregamos información en celdas vacías
BDD['Otro sitio de defunción'].fillna('NA', inplace=True)

#Verificamos categorías
sorted(BDD['Otro sitio de defunción'].unique())

#Ponemos todas las categorías en mayúsculas, ya que solo "domicilio" está en minúscula.
BDD['Otro sitio de defunción'] = BDD['Otro sitio de defunción'].str.upper()
#Unificamos las categorías 'PRISIÓN REFORMATORIOS'y 'PRISIÓNREFORMATORIOS'
BDD['Otro sitio de defunción'] = BDD['Otro sitio de defunción'].replace({'PRISIÓNREFORMATORIOS': 'PRISIÓN REFORMATORIOS'})

#Verificamos nuevamente categorías
sorted(BDD['Otro sitio de defunción'].unique())

#Verificamos datos nulos
BDD['Otro sitio de defunción'].isnull().sum()

#Verificamos categorías de 'Nombre institución' de defunción que no tiene datos nulos
sorted(BDD['Nombre institución de defunción'].unique())
#Sin novedades en esta columna

#Verificamos categorías de 'Tipo de defunción' de defunción que no tiene datos nulos
sorted(BDD['Tipo de defunción'].unique())
#Sin novedades en esta columna

#La variable 'Fecha de Defunción' no tiene datos nulos, pero se ajusta el formato
# Convertir a formato de fecha
BDD['Fecha de Defunción'] = pd.to_datetime(BDD['Fecha de Defunción'])
#Verificamos
BDD.info('Fecha de Defunción')

#Como la columna "Hora de defunción" tiene 1072 datos vacíos, pero la columna anterior de fecha, contiene también la hora y no tenía datos nulos, se elimina la columna de hora para no considerarla.
BDD = BDD.drop('Hora de defunción', axis=1)

#Verificamos categorías de la columna 'sexo' que no tiene datos nulos.
sorted(BDD['Sexo'].unique())
#Sin novedades en esta columna

#Agregamos la información a los datos vacíos de la columna "Estado civil" que tiene 51 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Estado civil'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna 'Estado civil'
sorted(BDD['Estado civil'].unique())

#Vamos a unificar algunas categorías
BDD['Estado civil'] = BDD['Estado civil'].replace({'ESTABA CASADO(A)': 'CASADO(A)',
                                                   'NO CASADO(A) Y DOS AÑOS O MAS CON SU PAREJA':'UNIÓN LIBRE',
                                                   'NO CASADO(A) Y MENOS DE DOS AÑOS CON SU PAREJA':'UNIÓN LIBRE',
                                                   'NO ESTABA CASADO(A) Y LLEVABA DOS AÑOS O MÁS VIVIENDO CON SU PAREJA':'UNIÓN LIBRE',
                                                   'NO ESTABA CASADO(A) Y LLEVABA MENOS DE DOS AÑOS VIVIENDO CON SU PAREJA':'UNIÓN LIBRE',
                                                   'ESTABA SEPARADO(A), DIVORCIADO(A)':'SEPARADO (A)',
                                                   'SEPARADO(A), DIVORCIADO(A)':'SEPARADO (A)',
                                                   'ESTABA SOLTERO(A)':'SOLTERO(A)',
                                                   'ESTABA VIUDO(A)':'VIUDO(A)'})

#Verificamos ajustes
sorted(BDD['Estado civil'].unique())

#Esta variable puede conmvertirse en una variable de tipo numérica de acuerdo con su naturaleza, ya que se puede ordenar menor a mayor nivel de compromiso que representa el estado civil, utilizando categorías numéricas
#Para lo cual agregaremos la columna "Nivel compromiso civil"
BDD['Nivel compromiso civil'] = BDD['Estado civil']

#Reajustamos las categorías
BDD['Nivel compromiso civil'] = BDD['Nivel compromiso civil'].replace({'SIN INFORMACIÓN': '0',
                                                   'SOLTERO(A)':'1',
                                                   'UNIÓN LIBRE':'2',
                                                   'CASADO(A)':'3',
                                                   'SEPARADO (A)':'4',
                                                   'VIUDO(A)':'5'})


#Convertimos la variable en entero
BDD['Nivel compromiso civil'] = BDD['Nivel compromiso civil'].astype(int)

#Verificamos ajustes
sorted(BDD['Nivel compromiso civil'].unique())

#Como la edad es una variable que podría tener gran significancia en esta base de datos, tener datos vacíos no sería útil y llenarlos con la media podría sesgar la información.
#Considerando que el conjunto de datos es de buenas dimensiones, se decide eliminar las filas con valores nulos en esta variable.
BDD = BDD.dropna(subset=['Edad'])

#Verificamos datos nulos
BDD['Edad'].isnull().sum()

#Ahora verificamos que los datos sean coherentes en cuanto a la edad
sorted(BDD['Edad'].unique())

#Como hay valores demasiado altos y esta podría ser una variable significativa, se eliminan las filas cuyos valores son mayores a 110 años 8 a partir de esa edad se observa un salto enorme que puede ser error de digitación)
#Convertimos la columna a tipo enteros
BDD['Edad'] = BDD['Edad'].astype(int)

#Eliminamos los valores mayores a 110
BDD = BDD[BDD['Edad'] <= 110]

#Verificamos nuevamente
sorted(BDD['Edad'].unique())

#Agregamos la información a los datos vacíos de la columna "Nivel educativo " que tiene 24 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Nivel educativo'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna 'Nivel educativo '
sorted(BDD['Nivel educativo'].unique())

#Vamos a unificar algunas categorías
BDD['Nivel educativo'] = BDD['Nivel educativo'].replace({'BASICA PRIMARIA': 'BÁSICA PRIMARIA',
                                                   'BASICA SECUNDARIA':'BÁSICA SECUNDARIA',
                                                   'MAESTRIA':'MAESTRÍA',
                                                   'MEDIA ACADEMICA O CLASICA':'MEDIA ACADÉMICA',
                                                   'MEDIA ACADÉMICA O CLÁSICA':'MEDIA ACADÉMICA',
                                                   'MEDIA TECNICA':'MEDIA TÉCNICA',
                                                   'TECNICA PROFESIONAL':'TÉCNICA PROFESIONAL',
                                                   'TECNOLOGICA':'TECNOLÓGICA',
                                                   'NORMALISTA':'MEDIA TÉCNICA'})

#Verificamos ajustes
sorted(BDD['Nivel educativo'].unique())

#Esta variable puede conmvertirse en una variable de tipo numériuca de acuerdo con su naturaleza, ya que se puede ordenar menor a mayor nivel de estudios utilizando categorías numéricas
#Para lo cual agregaremos la columna "Nivel educación"
BDD['Nivel educación'] = BDD['Nivel educativo']

#Reajustamos las categorías
BDD['Nivel educación'] = BDD['Nivel educación'].replace({'SIN INFORMACIÓN': '0',
                                                   'NINGUNO':'1',
                                                   'PREESCOLAR':'2',
                                                   'BÁSICA PRIMARIA':'3',
                                                   'BÁSICA SECUNDARIA':'4',
                                                   'MEDIA ACADÉMICA':'5',
                                                   'MEDIA TÉCNICA':'6',
                                                   'TÉCNICA PROFESIONAL':'7',
                                                   'TECNOLÓGICA':'8',
                                                   'PROFESIONAL':'9',
                                                   'ESPECIALIZACION':'10',
                                                   'MAESTRÍA':'11'})


#Convertimos la variable en entero
BDD['Nivel educación'] = BDD['Nivel educación'].astype(int)

#Verificamos ajustes
sorted(BDD['Nivel educación'].unique())

#Como la columna "Último curso fallecido" tiene 1141 datos vacíos, pero la columna anterior de "Nivel educativo", contiene información similar, se elimina esta columna de la base
BDD = BDD.drop('Último curso fallecido', axis=1)

"""##Variable OCUPACIÓN"""

#Agregamos la información a los datos vacíos de la columna "Ocupación" que tiene 205 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Ocupación'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna 'Ocupación'
sorted(BDD['Ocupación'].unique())

#Como son tantas categorías en esta variable, vamos a clasificar las categorías de "Ocupación" en una nueva columna de nombre "OCUPACION", tomando la parte general del oficio
#Renombramos la columna general
BDD.columns = BDD.columns.str.replace('Ocupación', 'Ocupación específica')

#Creamos la nueva columna
BDD['OCUPACION'] = BDD['Ocupación específica']

#Clasificamos las categorías agrupándolas así:

A= ['AGENTES COMERCIALES Y CORREDORES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'AGENTES DE COMPRAS, INTERMEDIARIOS Y CONSIGNATARIOS',
 'AGENTES DE LA ADMINISTRACIÓN PÚBLICA EN ADUANAS, IMPUESTOS Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'AGENTES DE LA POLICIA NACIONAL',
 'AGENTES Y POLICIAS DE TRANSITO']

B= 'AGENTES'

C= ['TÉCNICOS EN AGRONOMÍA, ZOOTECNIA Y SILVICULTURA',
 'TÉCNICOS EN DISEÑO Y DECORADORES',
 'TÉCNICOS TERAPEUTAS, QUIROPRÁCTICOS Y AFINES',
 'TÉCNICOS Y ASISTENTES EN FARMACIA',
 'TÉCNICOS Y ASISTENTES VETERINARIOS',
 'TÉCNICOS Y POSTSECUNDARIOS NO UNIVERSITARIOS EN CIENCIAS FÍSICAS, QUÍMICAS E INGENIERÍAS, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'TÉCNICOS, POSTSECUNDARIOS NO UNIVERSITARIOS EN INGENIERÍA CIVIL, ARQUITECTURA, AGRIMENSORES Y AFINES',
 'TÉCNICOS, POSTSECUNDARIOS NO UNIVERSITARIOS Y ASISTENTES DE SERVICIOS ADMINISTRATIVOS Y AFINES',
 'TÉCNICOS, POSTSECUNDARIOS NO UNIVERSITARIOS Y ASISTENTES EN OPERACIONES COMERCIALES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'T╔CNICOS E HIGIENISTAS DENTALES',
 'T╔CNICOS EN AGRONOM═A, ZOOTECNIA Y SILVICULTURA',
 'T╔CNICOS Y ASISTENTES EN FARMACIA']

D= 'TÉCNICOS'

E= ['OPERADORES DE EQUIPOS ÓPTICOS Y ELECTRÓNICOS, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'OPERADORES DE INSTALACIONES DE TRATAMIENTO DE AGUA Y AFINES',
 'OPERADORES DE MEZCLADORAS Y DE HORNOS DE VIDRIER═A Y AFINES',
 'OPERADORES DE MÁQUINAS PARA PROCESAR CARNE, PESCADO Y MARISCOS',
 'OPERADORES DE TELARES Y OTRAS MÁQUINAS TEJEDORAS',
 'OPERARIOS DE LA CONSERVACIÓN DE FRUTAS, LEGUMBRES, VERDURAS Y AFINES',
 'OPERARIOS DE LA FOTOGRAFÍA Y AFINES',
 'OPERARIOS DEL TRATAMIENTO DE LA MADERA',
 'OPERARIOS EN CEMENTO ARMADO, ENFOSCADORES Y AFINES',
 'OBREROS DE CARGA',
 'OBREROS DE LA CONSTRUCCIÓN DE EDIFICIOS',
 'OBREROS DE PESCA, CAZA Y TRAMPA',
 'OBREROS FORESTALES',
 'OBREROS Y PEONES AGROPECUARIOS DE LABRANZA Y DE INVERNADERO']

F='OPERARIOS'

G=['PROFESORES DE EDUCACIËN PRIMARIA',
 'PROFESORES DE EDUCACIËN SECUNDARIA',
 'PROFESORES DE EDUCACIÓN PRIMARIA',
 'PROFESORES DE EDUCACIÓN SECUNDARIA',
 'PROFESORES DE UNIVERSIDADES Y OTROS ESTABLECIMIENTOS DE EDUCACIËN SUPERIOR',
 'PROFESORES DE UNIVERSIDADES Y OTROS ESTABLECIMIENTOS DE EDUCACIÓN SUPERIOR',
 'PROFESORES E INSTRUCTORES DE EDUCACIËN ESPECIAL',
 'PROFESORES E INSTRUCTORES DE EDUCACIÓN ESPECIAL', 'PROFESIONALES DE LA EDUCACIËN, NO CLASIFICADOS BAJO OTROS EP═GRAFES',
 'PROFESIONALES DE LA EDUCACIÓN, NO CLASIFICADOS BAJO OTROS EPÍGRAFES']

H= 'PROFESORES'

I= [ 'VENDEDORES A DOMICILIO Y POR TELÉFONO',
 'VENDEDORES AMBULANTES',
 'VENDEDORES EN QUIOSCOS Y PUESTOS DE MERCADO',
 'VENDEDORES, DEMOSTRADORES DE TIENDAS Y ALMACENES']

J= 'VENDEDORES'

K=[ 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIËN Y OPERACIONES EN COMERCIO MAYORISTA Y MINORISTAS',
 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIÓN Y OPERACIONES EN AGRICULTURA, CAZA, SILVICULTURA Y PESCA',
 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIÓN Y OPERACIONES EN COMERCIO MAYORISTA Y MINORISTAS',
 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIÓN Y OPERACIONES EN CONSTRUCCIÓN Y OBRAS PÚBLICAS',
 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIÓN Y OPERACIONES EN INDUSTRIAS MANUFACTURERAS Y EXTRACTIVAS',
 'DIRECTORES GENERALES, DE EMPRESAS O ENTIDADES DE LA ADMINISTRACIËN P┌BLICA',
 'DIRECTORES Y GERENTES GENERALES DE EMPRESAS PRIVADAS',
 'DIRIGENTES Y ADMINISTRADORES DE ORGANIZACIONES DE EMPLEADORES, DE TRABAJADORES Y DE OTRAS DE INTERÉS SOCIOECONÓMICO']

L= 'DIRECTORES'

M= [ 'MECÁNICOS Y AJUSTADORES DE MÁQUINAS AGRÍCOLAS E INDUSTRIALES',
 'MECÁNICOS Y AJUSTADORES DE VEHÍCULOS DE MOTOR',
 'MECÁNICOS Y REPARADORES DE INSTRUMENTOS DE PRECISIÓN',
 'MEC┴NICOS Y AJUSTADORES DE VEH═CULOS DE MOTOR']

N= 'MECÁNICOS'

O= ['INGENIEROS CIVILES, INGENIEROS DE TRANSPORTE Y AFINES',
 'INGENIEROS ELÉCTRICOS, INGENIEROS ELECTRÓNICOS DE TELECOMUNICACIONES Y AFINES',
 'INGENIEROS INDUSTRIALES Y AFINES',
 'INGENIEROS MEC┴NICOS','AYUDANTE DE TALLER, MECÁNICA, VEHÍCULOS DE MOTOR Y AFINES']

P= 'INGENIEROS'

Q=['COORDINADORES Y SUPERVISORES DE ALMACENAMIENTO, ABASTECIMIENTO Y DISTRIBUCIÓN',
 'COORDINADORES Y SUPERVISORES DE PRODUCCIËN Y OPERACIONES EN CUIDADOS PERSONALES, LIMPIEZA Y SERVICIOS SIMILARES',
 'COORDINADORES Y SUPERVISORES DE PRODUCCIÓN Y OPERACIONES EN CUIDADOS PERSONALES, LIMPIEZA Y SERVICIOS SIMILARES',
 'COORDINADORES Y SUPERVISORES DE VENTAS Y COMERCIALIZACIÓN',
 'COORDINADORES Y SUPERVISORES EN MANDOS MEDIOS DE PRODUCCIÓN Y OPERACIONES EN EMPRESAS PÚBLICAS Y PRIVADAS, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'COORDINADORES Y SUPERVISORES FINANCIEROS Y ADMINISTRATIVOS',
 'OTROS COORDINADORES Y SUPERVISORES EN MANDOS MEDIOS DE EMPRESAS PÚBLICAS Y PRIVADAS, NO CLASIFICADAS BAJO OTROS EPÍGRAFES']

R= 'COORDINADORES'

S= ['CONDUCTORES DE BUSES, MICROBUSES Y COLECTIVOS',
 'CONDUCTORES DE CAMIONES Y VEHÍCULOS PESADOS',
 'CONDUCTORES DE CAMIONETAS Y VEHÍCULOS LIVIANOS',
 'CONDUCTORES DE TAXIS',
 'CONDUCTORES DE VEHÍCULOS ACCIONADOS A PEDAL O A BRAZO',
 'CONDUCTORES DE VEH═CULOS DE TRACCIËN ANIMAL']

T= 'CONDUCTORES'

U= [ 'AUXILIARES ADMINISTRATIVOS Y AFINES',
 'AUXILIARES DE ENFERMERÍA Y ODONTOLOGÍA',
 'AUXILIARES DE LA POLICIA NACIONAL',
'ASISTENTES DE COMERCIO EXTERIOR',
 'ASISTENTES DE ENSEÑANZA EN EDUCACIÓN PREESCOLAR', 'SECRETARIOS (AS)']

V= 'AUXILIARES - ASISTENTES'

W= ['MÉDICOS',
 'MÉDICOS VETERINARIOS Y ZOOTECNISTAS',
 'MÉDICOS, PROFESIONALES EN CIENCIAS DE LA SALUD Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
'ENFERMEROS(AS) PROFESIONALES']

X= 'MÉDICOS'

Y= ['AGRICULTORES DE CULTIVOS PERMANENTES (PLANTACIONES DE ÁRBOLES Y ARBUSTOS)',
 'AGRICULTORES DE CULTIVOS TRANSITORIOS','CRIADORES DE GANADO Y TRABAJADORES DE LA CR═A DE ANIMALES DOM╔STICOS DIVERSOS',
 'TRABAJADORES AGROPECUARIOS',
 'TRABAJADORES DE HUERTAS, INVERNADEROS, VIVEROS Y JARDINES',
 'TRABAJADORES PECUARIOS, GANADEROS Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'TRABAJADORES PECUARIOS, GANADEROS Y AFINES, NO CLASIFICADOS BAJO OTROS EP═GRAFES',]

Z= 'TRABAJOS EN EL CAMPO'

OTRO = ['ABOGADOS',  'ACOMPAÑANTES',
 'ACTIVIDADES NO ESPECIFICADAS',
 'ALBAÑILES, MAMPOSTEROS Y AFINES',
 'ALFAREROS Y AFINES (BARRO, ARCILLA Y ABRASIVOS)',
 'ANALISTAS DE SISTEMAS INFORMÁTICOS',
 'ARQUITECTOS Y URBANISTAS',
 'ARTESANOS DE LA MADERA Y MATERIALES SIMILARES',
 'ASEADORES Y FUMIGADORES DE OFICINAS, HOTELES Y OTROS ESTABLECIMIENTOS',
 'ATLETAS, DEPORTISTAS Y AFINES',
 'BOMBEROS Y RESCATISTAS',
 'BORDADORES Y AFINES',
 'CAJEROS Y EXPENDEDORES DE BILLETES',
 'CARNICEROS, PESCADEROS Y AFINES',
 'CARPINTEROS DE ARMAR Y DE BLANCO',
 'CATADORES Y CLASIFICADORES DE ALIMENTOS Y BEBIDAS',
 'COCINEROS Y AFINES',
 'COMPOSITORES, M┌SICOS Y CANTANTES',
 'COMPRADORES',
 'CONTADORES',
 'DESCANSAR, DORMIR, COMER O PARTICIPAR EN OTRAS ACTIVIDADES VITALES',
 'EBANISTAS Y AFINES',
 'ELECTRICISTAS DE OBRAS Y AFINES',
 'ELECTROTÉCNICOS',
 'ELECTROT╔CNICOS',
 'EMBALADORES MANUALES Y OTROS OBREROS DE LA INDUSTRIA MANUFACTURERA',
 'ENCARGADOS DE SERVICIOS DE TRANSPORTE',
 'ENSAMBLADORES DE MECANISMOS Y ELEMENTOS MECÁNICOS DE MÁQUINAS',
 'ESCRITORES, PERIODISTAS Y AFINES',
 'ESCULTORES, PINTORES Y AFINES',
 'ESPECIALISTAS EN ORGANIZACIÓN, ADMINISTRACIÓN DE EMPRESAS, ANÁLISIS FINANCIERO Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'ESTUDIANTE',
 'FONOAUDÍOLOGOS, FISIOTERAPEUTAS Y AFINES',
 'GUARDIANES DE PRISIÓN',
 'HERREROS Y FORJADORES',
 'HOGAR',
 'INSTALADORES Y REPARADORES DE TELÉGRAFOS, TELÉFONOS Y LÍNEAS ELECTRICAS',
 'JOYEROS, ORFEBRES Y PLATEROS',
 'LIMPIABOTAS Y OTROS TRABAJADORES CALLEJEROS',
 'MARINEROS DE CUBIERTA Y AFINES',
 'MENSAJEROS, PORTEADORES Y REPARTIDORES',
 'MESEROS, TABERNEROS Y AFINES',
 'NIÑERAS Y CUIDADORAS INFANTILES',
 'OCIO',
 'OFICIALES DE LA POLICÍA NACIONAL',
 'OFICIALES DE LAS FMS001',
 'OFICIALES Y OPERARIOS DE LA CONSTRUCCIÓN Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'OTRAS ACTIVIDADES ESPECÍFICAS',
 'OTRO TRABAJO',
 'OTROS ARTESANOS, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'OTROS TRABAJADORES DE SERVICIOS PERSONALES A PARTICULARES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'OTROS TRABAJADORES DE SERVICIOS PERSONALES A PARTICULARES, NO CLASIFICADOS BAJO OTROS EP═GRAFES',
 'PANADEROS, PASTELEROS Y CONFITEROS',
 'PELUQUEROS, ESPECIALISTAS EN TRATAMIENTOS DE BELLEZA Y AFINES',
 'PENSIONADO',
 'PERSONAL DE LOS SERVICIOS DE PROTECCIËN Y SEGURIDAD, NO CLASIFICADO BAJO OTROS EP═GRAFES',
 'PERSONAL DE LOS SERVICIOS DE PROTECCIÓN Y SEGURIDAD, NO CLASIFICADO BAJO OTROS EPÍGRAFES',
 'PESCADORES',
 'PINTORES DECORADORES DE VIDRIO, CERÁMICA Y OTROS MATERIALES',
 'PINTORES, BARNIZADORES Y ENLACADORES DE ARTÍCULOS METÁLICOS Y AFINES',
 'PINTORES, BARNIZADORES Y ENLACADORES DE ART═CULOS MET┴LICOS Y AFINES',
 'PINTORES, EMPAPELADORES Y AFINES',
 'PROFESIONALES DEL DERECHO, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'PROFESIONALES DEL DERECHO, NO CLASIFICADOS BAJO OTROS EP═GRAFES',
 'PSICÓLOGOS',
 'RECOLECTORES DE MATERIAL RECICLABLE',
 'REPRESENTANTES COMERCIALES Y TÉCNICOS DE VENTAS',
 'REVISORES, GUARDAS Y COBRADORES DE LOS SERVICIOS DE TRANSPORTE',
 'SACERDOTES Y RELIGIOSOS DE DISTINTAS DOCTRINAS',
 'SASTRES, MODISTOS COSTUREROS SOMBREREROS Y AFINES',
 'SOLDADORES Y OXICORTADORES',
 'TRABAJADORES DE LOS CUIDADOS PERSONALES Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'TRABAJADORES DE LOS CUIDADOS PERSONALES Y AFINES, NO CLASIFICADOS BAJO OTROS EP═GRAFES',
 'TRABAJADORES SOCIALES Y AFINES',
 'TRABAJO PARA OBTENER INGRESOS',
 'VIGILANTES Y CELADORES',
 'ZAPATEROS Y AFINES']

OTRAS = 'OTRAS OCUPACIONES ESPECÍFICAS'

#Ahora generamos las nuevas categorías
BDD['OCUPACION'] = BDD['OCUPACION'].replace(A,B)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(C,D)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(E,F)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(G,H)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(I,J)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(K,L)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(M,N)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(O,P)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(Q,R)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(S,T)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(U,V)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(W,X)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(Y,Z)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(OTRO,OTRAS)
BDD['OCUPACION'] = BDD['OCUPACION'].replace({'SIN INFORMACION':'SIN INFORMACIÓN'})

#Verificamos ajustes
sorted(BDD['OCUPACION'].unique())

"""##Continuación de verificación y limpieza de variables"""

#Agregamos la información a los datos vacíos de la columna "Cultura, pueblo, rasgos físicos" que tiene 22 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Cultura, pueblo, rasgos físicos'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Cultura, pueblo, rasgos físicos'].unique())

#Vamos a unificar algunas categorías
BDD['Cultura, pueblo, rasgos físicos'] = BDD['Cultura, pueblo, rasgos físicos'].replace({'NEGRO(A), MULATO(A), AFRO COLOMBIANO(A) O AFRO DESCENDIENTE': 'NEGRO(A), MULATO(A), AFROCOLOMBIANO(A) O AFRODESCENDIENTE',
                                                   'NINGUNA DE LAS ANTERIORES':'NINGUNA',
                                                   'NINGUNO DE LOS ANTERIORES':'NINGUNA'})

#Verificamos ajustes
sorted(BDD['Cultura, pueblo, rasgos físicos'].unique())

#Como los datos son aplicados a Colombia y las variables "País de residencia", "Departamento de residencia" y "Municipio de residencia" tienen 2 datos nulos cada una, se procede a eliminar estas dos filas para cada una.
BDD = BDD.dropna(subset=['País de residencia', 'Departamento de residencia', 'Municipio de residencia'])

#Verificamos datos nulos
BDD.isnull().sum()

#Verificamos categorías de la columna DE MUNICIPIO RESIDENCIA
sorted(BDD['Municipio de residencia'].unique())

#Vamos a unificar algunas categorías
BDD['Municipio de residencia'] = BDD['Municipio de residencia'].replace({'BOLÍVAR':'BOLIVAR',
                                                                              'BUGA':'GUADALAJARA DE BUGA',
                                                                              'ALTOS DE GUADALAJARA':'ALTOS DEL GUADALAJARA',
                                                                              'CALI (SANTIAGO DE CALI)':'CALI',
                                                                              'CALIMA (DARIEN)':'CALIMA',
                                                                              'GUACARÍ':'GUACARI',
                                                                              'JAMUNDÍ':'JAMUNDI',
                                                                              'LA UNIÓN':'LA UNION',
                                                                              'RIOFRÍO':'RIOFRIO',
                                                                              'TULUA':'TULUÁ'})
#Verificamos ajustes
sorted(BDD['Municipio de residencia'].unique())

#Verificamos categorías de la columna DE DEPARTAMENTO RESIDENCIA
sorted(BDD['Departamento de residencia'].unique())

#Vamos a unificar algunas categorías
BDD['Departamento de residencia'] = BDD['Departamento de residencia'].replace({'QUINDIO':'QUINDÍO'
})
#Verificamos ajustes
sorted(BDD['Departamento de residencia'].unique())

#Agregamos la información a los datos vacíos de la columna "Area de residencia" que tiene 4 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Area de residencia'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Area de residencia'].unique())

#Vamos a unificar algunas categorías
BDD['Area de residencia'] = BDD['Area de residencia'].replace({'"CENTRO POBLADO (Inspección,\r\ncorregimiento o caserío)"':'CENTRO POBLADO (INSPECCIÓN, CORREGIMIENTO O CASERÍO)'})

#Verificamos ajustes
sorted(BDD['Area de residencia'].unique())

#Agregamos la información a los datos vacíos de la columna "Barrio de fallecido" que tiene 210 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Barrio de fallecido'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Barrio de fallecido'].unique())

#Vamos a unificar algunas categorías
BDD['Barrio de fallecido'] = BDD['Barrio de fallecido'].replace({'ACUARELA':'ACUARELAS',
                                                                 'ALTO BONITO':'ALTOBONITO',
                                                                 'ALTOS DE GUADALAJARA':'ALTOS DEL GUADALAJARA',
                                                                 'BALCONESL DEL NORTE':'BALCONES DEL NORTE',
                                                                 'BELLAVISTA':'BELLA VISTA',
                                                                 'DIVINNO NIÑO':'DIVINO NIÑO',
                                                                 'DIVINO NINO':'DIVINO NIÑO',
                                                                 'EL DIVINO NIÑO':'DIVINO NIÑO',
                                                                 'ENTRE VALLES':'ENTREVALLES',
                                                                 'FUENMAYOR': 'FUEN MAYOR',
                                                                 'GONZALO ECHEVERRI':'GONZALO ECHEVERRY',
                                                                 'JORGE ELIZER GAITAN':'JORGE ELIECER GAITAN',
                                                                 'LA CONFORNIA':'LA CONCORDIA',
                                                                 'LA CORCORDIA':'LA CONCORDIA',
                                                                 'LA MARCED':'LA MERCED',
                                                                 'LAS MERCED': 'LA MERCED',
                                                                 'LA REVOLUCION':'LA REVOLUCIÓN',
                                                                 'LA REVOLUSION':'LA REVOLUCIÓN',
                                                                 'REVOLUCION':'LA REVOLUCIÓN',
                                                                 'MARA LUISA DE LA ESPADA': 'MARIA LUISA  LA ESPADA',
                                                                 'MARIA LUISA': 'MARIA LUISA DE LA ESPADA',
                                                                 'MARIA LUISA  LA ESPADA':'MARIA LUISA DE LA ESPADA',
                                                                 'MARIA LUISA LA EPSADA':'MARIA LUISA DE LA ESPADA',
                                                                 'MARIA LUISA LA ESPADA':'MARIA LUISA DE LA ESPADA',
                                                                 'MARIA LUISA  LA ESPADA':'MARIA LUISA DE LA ESPADA',
                                                                 'NO RECUERDA':'NO IDENTIFICADO',
                                                                 'NO SABE':'NO IDENTIFICADO',
                                                                 'OTROS':'OTRO',
                                                                 'OTROS BARRIOS':'OTRO',
                                                                 'SD':'OTRO',
                                                                 'RICAUTE':'RICAURTE',
                                                                 'SAN JOSE DE LAS PALMAS':'SAN JOSÉ DE LAS PALMAS',
                                                                 'SIN DATOS': 'SIN INFORMACIÓN',
                                                                 'SIN INFORMACION':'SIN INFORMACIÓN',
                                                                 'UNI NORTE': 'UNINORTE'})

#Verificamos ajustes
sorted(BDD['Barrio de fallecido'].unique())

#Verificamos categorías de la columna "Vereda del fallecido" que no tiene datos nulos
sorted(BDD['Vereda del fallecido'].unique())

#Vamos a unificar algunas categorías
BDD['Vereda del fallecido'] = BDD['Vereda del fallecido'].replace({'CHAMBINBAL':'CHAMBIMBAL',
                                                                    'CHAMBINBAL SAN ANTONIO':'CHAMBIMBAL SAN ANTONIO',
                                                                    'MEDIACANOA':'MEDIA CANOA',
                                                                    'MIRAVLLE':'MIRAVALLE',
                                                                    'NO DIENTIFICADA':'NO IDENTIFICADA',
                                                                    'SIN INFORMACION':'SIN INFORMACIÓN',
                                                                    'chambimbal la campiña':'CHAMBIMBAL LA CAMPIÑA',
                                                                   'el manantial':'EL MANANTIAL',
                                                                   'el vinculo':'EL VINCULO'})
#Verificamos ajustes
sorted(BDD['Vereda del fallecido'].unique())

#Agregamos la información a los datos vacíos de la columna "Seguridad social" que tiene 27 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Seguridad social'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Seguridad social'].unique())

#Esta variable puede conmvertirse en una variable de tipo numérica de acuerdo con su naturaleza, ya que se puede ordenar menor a mayor nivel de seguridad social utilizando categorías numéricas
#Para lo cual agregaremos la columna "Nivel SS"
BDD['Nivel SS'] = BDD['Seguridad social']

#Reajustamos las categorías
BDD['Nivel SS'] = BDD['Nivel SS'].replace({'SIN INFORMACIÓN': '0',
                                                   'NO ASEGURADO':'1',
                                                   'EXCEPCIÓN':'2',
                                                   'SUBSIDIADO':'3',
                                                   'CONTRIBUTIVO':'4',
                                                   'ESPECIAL':'5'})


#Convertimos la variable en entero
BDD['Nivel SS'] = BDD['Nivel SS'].astype(int)

#Verificamos ajustes
sorted(BDD['Nivel SS'].unique())

#Verificamos categorías de la columna "Entidad administradora de salud" que no tiene datos nulos
sorted(BDD['Entidad administradora de salud'].unique())

#Vamos a unificar algunas categorías
BDD['Entidad administradora de salud'] = BDD['Entidad administradora de salud'].replace({'ASMET SALUD EPS SAS -CM':'ASMET SALUD EPS SAS',
                                                                                         'ASMET SALUD ESS - ASOCIACION MUTUAL LA ESPERANZA':'ASMET SALUD EPS SAS',
                                                                                         'ASOCIACIÓN MUTUAL LA ESPERANZA - ASMET SALUD':'ASMET SALUD EPS SAS',
                                                                                         'ASOCIACIÓN MUTUAL LA ESPERANZA - ASMET SALUD -CM':'ASMET SALUD EPS SAS',
                                                                                         'ASOCIACIÓN MUTUAL LA ESPERANZA ASMET  SALUD-CM':'ASMET SALUD EPS SAS',
                                                                                         'ASOCIACIÓN MUTUAL EMPRESA SOLIDARIA DE SALUD DE NARIÑO - EMSSANAR E.S.S. -CM':'EMSSANAR S.A.S.',
                                                                                         'ASOCIACIÓN MUTUAL EMPRESA SOLIDARIA DE SALUD DE NARIÑO E.S.S. EMSSANAR E.S.S.-CM':'EMSSANAR S.A.S.',
                                                                                         'CAFESALUD E.P.S.':'CAFESALUD E.P.S.  S.A.',
                                                                                         'COMFENALCO VALLE':'COMFENALCO  VALLE  E.P.S.',
                                                                                         'COMPENSAR   E.P.S.-CM':'COMPENSAR   E.P.S.',
                                                                                         'COMPENSAR E.P.S.':'COMPENSAR   E.P.S.',
                                                                                         'COMPENSAR E.P.S. -CM':'COMPENSAR   E.P.S.',
                                                                                         'COOMEVA   E.P.S.  S.A.':'COOMEVA E.P.S. S.A.',
                                                                                         'COOMEVA E.P.S. S.A. -CM':'COOMEVA E.P.S. S.A.',
                                                                                         'COOMEVA MEDICINA PREPAGADA S.A.':'COOMEVA E.P.S. S.A.',
                                                                                         'COOPERATIVA DE SALUD Y DESARROLLO INTEGRAL ZONA SUR ORIENTAL DE CARTAGENA LTDA. - COOSALUD E.S.S. -CM':'COOPERATIVA DE SALUD Y DESARROLLO INTEGRAL ZONA SUR ORIENTAL DE CARTAGENA LTDA. - COOSALUD E.S.S.',
                                                                                         'E.P.S. SANITAS':'E.P.S.  SANITAS  S.A.',
                                                                                         'EPS SANITAS - CM':'E.P.S.  SANITAS  S.A.',
                                                                                         'EMSSANAR ESS - ASOCIACION MUTUAL EMPRESA SOLIDARIA DE SALUD':'EMSSANAR S.A.S.',
                                                                                         'ENTIDAD COOPERATIVA SOLIDARIA DE SALUD DEL NORTE DE SOACHA - ECOOPSOS -CM':'ENTIDAD COOPERATIVA SOLIDARIA DE SALUD DEL NORTE DE SOACHA - ECOOPSOS',
                                                                                         'EPS S.O.S. S.A. - EPS SERVICIO OCCIDENTAL DE SALUD  S.A.': 'EPS SERVICIO OCCIDENTAL DE SALUD  S.A. - EPS S.O.S. S.A.-CM',
                                                                                         'EPS Y MEDICINA PREPAGADA SURAMERICANA S.A': 'EPS SURA',
                                                                                         'EPS Y MEDICINA PREPAGADA SURAMERICANA S.A -CM': 'EPS SURA',
                                                                                         'EPS Y MEDICINA PREPAGADA SURAMERICANA S.A-CM': 'EPS SURA',
                                                                                         'EPS Y MEDICINA PREPAGADA SURAMERICANA S.A.': 'EPS SURA',
                                                                                         'FAMISANAR E.P.S. LTDA - CAFAM - COLSUBSIDIO -CM':'FAMISANAR E.P.S. LTDA - CAFAM - COLSUBSIDIO',
                                                                                         'MEDIMÁS EPS S.A.S. CONTRIBUTIVO':'MEDIMÁS EPS S.A.S.',
                                                                                         'MEDIMÁS EPS S.A.S. SUBSIDIADO':'MEDIMÁS EPS S.A.S.',
                                                                                         'MEDIMÁS EPS S.A.S. -CM':'MEDIMÁS EPS S.A.S.',
                                                                                         'LA NUEVA EPS S.A.-CM':'NUEVA EPS S.A',
                                                                                         'NUEVA EPS S.A.':'NUEVA EPS S.A',
                                                                                         'NUEVA EPS S.A. -CM':'NUEVA EPS S.A',
                                                                                         'NUEVA EPS SA':'NUEVA EPS S.A',
                                                                                         'SALUD TOTAL E.P.S. -CM':'SALUD TOTAL S.A.',
                                                                                         'SALUD TOTAL S.A. ENTIDAD PROMOTORA DE SALUD':'SALUD TOTAL S.A.',
                                                                                         'SAVIA SALUD E.P.S. -CM': 'SAVIA SALUD E.P.S.',
                                                                                         'SERVICIO OCCIDENTAL DE SALUD - S.O.S. S.A. -CM': 'SERVICIO OCCIDENTAL DE SALUD - S.O.S. S.A.'})
#Verificamos ajustes
sorted(BDD['Entidad administradora de salud'].unique())

#Agregamos la información a los datos vacíos de la columna "Probable manera de muerte" que tiene 640 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Probable manera de muerte'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Probable manera de muerte'].unique())
#No hay más ajustes para esta columna

#Como las variables "longitud", "latitud" y localización pueden aportarnos información espacial visual de los datos, se conservan y se reemplazan los datos nulos con cero (894 datos nulos cada uno)
BDD['longitud'].fillna(0, inplace=True)
BDD['latitud'].fillna(0, inplace=True)
BDD['Geolocalización'].fillna('NA', inplace=True)

#Confirmamos el tipo object para la variable de geolocalización
BDD['Geolocalización'] = BDD['Geolocalización'].astype(object)

#Verificamos los datos nulos
BDD.isnull().sum()

#No quedan datos nulos en las variables, y para garantizar que la información de las variables "año" y "mes" sean correctas, se reemplaza la información de estas columnas a partir de la variable "Fecha de Defunción"
# Extraer el nombre del mes y agregarlo en la columna 'mes'
BDD['mes'] = BDD['Fecha de Defunción'].dt.strftime('%B')
# Extraer el año y agregarlo en columna 'año'
BDD['año'] = BDD['Fecha de Defunción'].dt.year

#Verificamos el contenido de las variables
BDD[['año', 'mes']]

#Hemos finalizado la limpieza y preprocesamiento de todas las variables en la base de datos.

#Verificamos las dimensiones finales del conjunto de datos
BDD.shape

"""#Exploración y análisis de datos"""

#ahora haremos una exploración rápida de las variables
EXP= sv.analyze(BDD)
EXP.show_notebook()

"""Teniendo en cuenta la exploración rápida de los datos para cada variable, tenemos lo siguiente: Todos los datos de defunciones de la base, son de personas que vivían y murieron en Colombia, del departamento del Valle del Cauca, principalmente en el municipio de Guadalajara de Buga con el 99%, sin embargo sus municipios de residencia variaban entre Buga con el 73% y Guacari con un 7%. La principal área de defunción ha sido la cabecera municipal con el 96% de los casos en diferentes barrios, 2% en área rural dispersa y 1% en un centro poblado.
En cuanto al sitio específico de defunción, el 64% ha fallecido en el hospital, el 30% en su casa, 5% en vías públicas y el otro 1% en otros lugares.
Las instituciones de salud en las que se han presentado mayor cantidad de fallecidos son la Fundación Hospital San José con el 74% de los casos, 6% en la E.S.E. Hospital Divino Niño y hay un 15% sin información.
Para el tipo de defunción, se ha tenido un 100% de defunciones de tipo No fetal, la mayoría de fallecidos han sido del sexo Masculino con el 56%, el 25% de fallecidos estaban viudos, el 23% estaban casados, el 22% solteros. La mayoría de fallecidos eran mayores de 50 años de edad, su nivel educativo era principalmente básica primaria (55%) y en segundo lugar básica secundaria con 15%. El 30% se ocupaba de su hogar y se tiene un 42% sin esta información de ocupación. En cuanto a rasgos físicos y cultura, la mayoría no tenía alguna clasificación (98%), solo un 2% era afrocolombiano y menos del 1% indígena.

La mayoría de fallecidos contaban con seguridad social: 48% Contributivo y 48% subsidiado, la EPS era principalmente Nueva EPS con el 31% y luego EMSSANAR E.S.S. con el 17%.

La muerte natural por enfermedad con un 65% es la que más se presentó. Se tiene un 25% de los casos sin información.

Los datos son principalmente de los años 2021 y 2022 y los meses con mayor cantidad d efallecidos fueron los meses de Julio y enero con 11% cada uno y luego Junio con el 10% de los casos.
"""

# crear dataset para Cantidad de defunciones por Sexo y por año

BASE_A = BDD.groupby(['Sexo','año'])[['Fecha de Defunción']].count().reset_index()

# crear gráfica
fig_A = px.bar(BASE_A, x = 'año', y ='Fecha de Defunción', color ='Sexo', barmode = 'group')

# agregar detalles a la gráfica
fig_A.update_layout(
    title = '<b>Cantidad de defunciones por Sexo y por año<b>',
    xaxis_title = 'Año de defunción',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_A.show()

"""Tanto en 2021 como en 2022, la mayoría de fallecidos fueron del sexo masculino."""

# Crear dataset para Cantidad de defunciones por la Probable manera de muerte y por año
BASE_C = BDD.groupby(['Probable manera de muerte', 'año'])[['Fecha de Defunción']].count().reset_index()

# Crear gráfica
fig_C = px.bar(BASE_C, x='año', y='Fecha de Defunción', color='Probable manera de muerte', barmode='relative')

# Agregar detalles a la gráfica
fig_C.update_layout(
    title='<b>Cantidad de defunciones por la Probable manera de muerte y por año<b>',
    xaxis_title='Año de defunción',
    yaxis_title='Número de defunciones',
    template='simple_white',
    title_x=0.5
)

fig_C.show()

"""Tanto en 2021 como en 2022, la mayoría de muertes fueron de manera natural por enfermedad, sin embargo hay una buena proporción sin información en el 2022. En 2021 se dió una porción de homicidios y en 2022 se cataloga como muerte no natural."""

import plotly.express as px

# Crear dataset para Cantidad de defunciones por Edad y por año
BASE_E = BDD.groupby(['Nivel educativo', 'Estado civil'])[['Fecha de Defunción']].count().reset_index()

# Crear gráfica
fig_E = px.bar(BASE_E, x='Estado civil', y='Fecha de Defunción', color='Nivel educativo', barmode='stack')

# Agregar detalles a la gráfica
fig_E.update_layout(
    title='<b>Cantidad de defunciones por Estado civil y por Nivel educativo<b>',
    xaxis_title='Estado civil',
    yaxis_title='Número de defunciones',
    template='simple_white',
    title_x=0.5
)

fig_E.show()

# crear dataset para Cantidad de defunciones por mes y por Probable manera de muert

BASE_F = BDD.groupby(['mes','Probable manera de muerte'])[['Fecha de Defunción']].count().reset_index()

# crear gráfica
fig_F = px.bar(BASE_F, x = 'mes', y ='Fecha de Defunción', color ='Probable manera de muerte', barmode = 'stack')

# agregar detalles a la gráfica
fig_F.update_layout(
    title = '<b>Cantidad de defunciones por mes y por Probable manera de muerte<b>',
    xaxis_title = 'Probable manera de muerte',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

"""la mayoría de meses domina la mkuerte por enfermedad, en todos está presente  la muerte por homicidio y una baja proporción por accidentes."""

# crear dataset para Cantidad de defunciones porEdad y por Probable manera de muert

BASE_G = BDD.groupby(['Edad','Probable manera de muerte'])[['Fecha de Defunción']].count().reset_index()

# crear gráfica
fig_G = px.bar(BASE_G, x = 'Probable manera de muerte', y ='Fecha de Defunción', color ='Edad', barmode = 'group')

# agregar detalles a la gráfica
fig_G.update_layout(
    title = '<b>Cantidad de defunciones por Edad y por Probable manera de muerte<b>',
    xaxis_title = 'Probable manera de muerte',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_G.show()

"""Cuando se observa la información pór manera de morir y su distribución de edades, se puede decir que la muerte por enfermedad predomina en personas mayores de 50 años, mientras que para el resto de maneras predominan edades inferiores a 50 años."""

#Veamos la Entidad administradora de salud para las defunciones cuya "probable manera de muerte" fue la "NATURAL (ENFERMEDAD)"
# crear dataset para MUERTE NATURAL

base_H = BDD[BDD['Probable manera de muerte'].isin(['NATURAL (ENFERMEDAD)'])]
base_H = base_H.groupby(['Probable manera de muerte','Entidad administradora de salud'])[['Fecha de Defunción']].count().reset_index()

# crear gráfica
fig_H = px.bar(base_H, x='Entidad administradora de salud', y='Fecha de Defunción', color ='Probable manera de muerte', barmode ='group', title ='<b>Entidad administradora de salud para las defunciones cuya "probable manera de muerte" fue la "NATURAL (ENFERMEDAD)"<b>')

# agregar detalles a la gráfica
fig_H.update_layout(
    xaxis_title = 'Entidad administradora de salud',
    yaxis_title = 'N° de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_H.show()

"""Cuando se quiere ver la información de fallecidos por enfermedad y su EPS, se tiene que la mayoría pertenecían a La Nueva EPS, y EMSSANAR"""

# Matriz de correlación
plt.figure(figsize=(20,10))
c= BDD.corr()
sns.heatmap(c, annot=True)
#Solo se observa una correlación baja entre la edad y el nivel de compromiso.



"""#Aplicación de Algoritmo K-means

##Creación de dataset
"""

#Para poder continuar, debemos ajustar la base y sus variables, pasándolas a númericas

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Separar variables numéricas y categóricas (Esto es importante para poder aplicar diferentes transformaciones a cada tipo de variable)
numeric_features = ['Edad', 'año', 'Nivel educación', 'Nivel compromiso civil', 'Nivel SS']
categorical_features = ['Municipio defunción', 'Área defunción','Sexo','Barrio de fallecido','Entidad administradora de salud', 'Probable manera de muerte','mes']

# Crear transformador de columnas (Para las variables numéricas, se aplica una estandarización ( StandardScaler), que escala las características de manera que tengan una media de 0 y una desviación estándar de 1.
#Para las variables categóricas, se aplica un codificador one-hot ( OneHotEncoder), que convierte las variables categóricas en una representación binaria.)

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(), categorical_features)])

# Crear un pipeline
pipeline = Pipeline(steps=[('preprocessor', preprocessor)])

# Aplicar el preprocesamiento a tus datos
X_processed = pipeline.fit_transform(BDD)
#El resultado ( X_processed) es la base de datos con las transformaciones aplicadas.

#Creación de clusters desde la base procesada

# Obtener el número de muestras y características (n_samples representa el número de muestras (filas), y n_features representa el número de características (columnas).)
n_samples, n_features = X_processed.shape

# Definir el número de centros (clusters)
centers = 3 ###ESTO PODEMOS CAMBIARLO

# Definir la desviación estándar (cluster_std)
cluster_std = 1.0 ###ESTO PODEMOS CAMBIARLO

# Generar el conjunto de datos sintético
synthetic_data, true_labels = make_blobs(n_samples=n_samples,
                                         n_features=n_features,
                                         centers=centers,
                                         cluster_std=cluster_std,
                                         random_state=42)

# Extraer las características de la base de datos en un arreglo NumPy
features = synthetic_data

#Mostrar las cinco primeras filas
features[:5]

#En resumen, se trata de una matriz dispersa de 5 filas y 1354 columnas con 150 elementos distintos de cero almacenados.

#Esto permite ver una muestra inicial de las etiquetas reales asociadas a las primeras muestras del conjunto de datos.
true_labels[:5]

"""##Preprocesamiento de los datos"""

from sklearn.preprocessing import StandardScaler
from scipy.sparse import csr_matrix

# Convertir a un formato compatible con scipy.sparse
X_sparse = csr_matrix(features)

# Crear un objeto StandardScaler para matrices dispersas
scaler = StandardScaler(with_mean=False) #no se centran las características en cero

# Aplicar el escalamiento
scaled_features = scaler.fit_transform(features)

#obtener las primeras cinco filas de un conjunto de datos que ha sido escalado. Esto mostrará una muestra de cómo se ven las primeras cinco muestras después de aplicar la escalada
scaled_features[:5]

"""##Algoritmo K-means"""

# Creación de modelo de Kmeans
kmeans = KMeans(init="random",
                n_clusters=3,
                n_init=10,
                max_iter=100,
                random_state=42)

# Ajuste de algoritmo a caracteristicas escaladas
kmeans.fit(scaled_features)

# el valor del SSE mas bajo
print("valor del SSE mas bajo: ", kmeans.inertia_)

# Coordenadas de los centroides
print(kmeans.cluster_centers_)

# Numero de interaciones necesarias para converger
print("Numero de iteraciones: ",kmeans.n_iter_)

# Etiqueta de los datos generadas por Kmeans
kmeans.labels_[:5]

#Predecir valores de etiquetas
label = kmeans.fit_predict(scaled_features)

print(label)

#Obtener valores unicos de cluster
# definidos correctamente y que estén en un formato que pueda ser indexado de esta manera.)

u_labels = np.unique(label)

#Diagramar el resultado:
for i in u_labels:
    plt.scatter(scaled_features[label == i,0] , scaled_features[label == i,1] , label = i)
plt.legend()
plt.show()

"""##Elección del número apropiado de clústeres

###Método del codo
"""

# Argumentos del algoritmo
kmeans_kwargs = {"init": "random", "n_init": 10, "max_iter": 300, "random_state": 42}
# Lista que almacena los valores de SSE para cada valor K
sse = []
# Ciclo para entrenar algoritmos de kmeans con cada valor de k
for k in range(1, 11):
  kmeans = KMeans(n_clusters=k, **kmeans_kwargs)
  kmeans.fit(scaled_features)
  sse.append(kmeans.inertia_)

# Visualización de resultados
plt.style.use("fivethirtyeight")
plt.plot(range(1, 11), sse)
plt.xticks(range(1, 11))
plt.xlabel("Number of Clusters")
plt.ylabel("SSE")
plt.show()

# Seleccion automatica del numero k
kl = KneeLocator(range(1, 11),
                 sse, curve="convex",
                 direction="decreasing")

kl.elbow

"""###Coeficiente de silueta"""

# Lista contiene los coeficientes de silueta para cada k
silhouette_coefficients = []
# Fíjate que empiezas con 2 grupos para el coeficiente de silueta
for k in range(2, 11):
  kmeans = KMeans(n_clusters=k, **kmeans_kwargs)
  kmeans.fit(scaled_features)
  score = silhouette_score(scaled_features, kmeans.labels_)
  silhouette_coefficients.append(score)

# Visualización de resultados
plt.style.use("fivethirtyeight")
plt.plot(range(2, 11), silhouette_coefficients)
plt.xticks(range(2, 11))
plt.xlabel("Number of Clusters")
plt.ylabel("Silhouette Coefficient")
plt.show()

"""#Aplicación de algoritmo Hierarchical Clustering"""

BDD.head()

# Separación de caracteristicas
X = BDD.iloc[:,24:27]
print(X.shape)
X.head()

"""##Uso del dendrograma para encontrar el número óptimo de clusters"""

from scipy.cluster.hierarchy import dendrogram, linkage
import scipy.cluster.hierarchy as sch

# Función de vinculación para agrupar datos según similud
Z = linkage(X, method='ward', metric='euclidean')
Z[:5]

dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))
plt.title('Dendrogram')
plt.xlabel('Customers')
plt.ylabel('Euclidean distances')
plt.show()

# Dibujo del dendograma
labelList = list(BDD['Municipio defunción'])

plt.figure(figsize=(13, 12))
dendrogram(
    Z,
    orientation='right',
    labels=labelList,
    distance_sort='descending',
    show_leaf_counts=False,
    leaf_font_size=16
)
plt.show()

"""##Entrenamiento del modelo de agrupación jerárquica en el conjunto de datos"""

from sklearn.cluster import AgglomerativeClustering

hc = AgglomerativeClustering(n_clusters = 2, metric = 'euclidean', linkage = 'ward')

y_hc = hc.fit_predict(X)

print(hc.labels_)

"""##Incorporando los clusters al dataframe original"""

BDD['cluster'] = y_hc
BDD.head()
