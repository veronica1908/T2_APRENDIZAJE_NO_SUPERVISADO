#Preparamos complementos, librerías y bases disponibles
import warnings

warnings.filterwarnings("ignore")

!pip install pandas numpy sweetviz seaborn matplotlib scikit-learn
!pip install kneed

#Instalación de complemento
!pip install sweetviz

#importar librerias
#importar librerias
import pandas as pd
import numpy as np
import sweetviz as sv
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import kneed as kd

from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import ShuffleSplit
from sklearn import datasets
import numpy as np
import pandas as pd
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from kneed import KneeLocator
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_score
%matplotlib inline


#Traemos la base de datos

# Lectura de los datos
BDD = pd.read_csv("https://raw.githubusercontent.com/veronica1908/T2_APRENDIZAJE_NO_SUPERVISADO/main/BASE_SIN_PROCESAR.csv", sep = ',')

#Verificamos que la base haya cargado y pueda visualizarse
BDD.head()

#Verificamos las dimensiones de la base
BDD.shape

# Verificamos cuáles son las variables de la base, vemos información de las variables, como datos NO nulos y tipo de dato
BDD.info()

# Vemos la cantidad de datos nulos por variable
BDD.isnull().sum()

#Existen muchos datos nulos y como las dimensiones de la base son considerablemente grandes, se eliminarán las filas cuyos datos nulos pertenezcan a variables núméricas importantes y para las filas de texto, se agregará "Sin información"

#Vamos a verificar cada columna para tomar decisiones en el ajuste de datos de cada una de ellas
#Empezamos con la columna "N°", la cual tiene 1141 datos nulos-vacíos
print(BDD['N°'])

#La columna N° es un identificador de características o filas de la base y los valores están asignados como identificador consecutivo, vamos a llenar esta columna con números los consecutivos.
BDD['N°'] = range(1, len(BDD) + 1)

#Verificamos que no queden datos nulos-vacíos
BDD['N°'].isnull().sum()

#Como la columna "Departamento defunción" no tiene datos nulos, verificamos entonces sus categorías en orden alfabético para detectar posibles errores en el ingreso de datos
sorted(BDD['Departamento defunción'].unique())
#Verificamos la cantidad de datos por departamento
BDD['Departamento defunción'].value_counts()

#Como la gran mayoría de datos pertenecen al departamento del VALLE DEL CAUCA, nos centraremos en estos datos y eliminaremos los que pertenecen a otros departamentos
dep_elim = ['CUNDINAMARCA','SANTA FE DE BOGOTÁ','RISARALDA','TOLIMA','NARIÑO','CASANARE','GUAVIARE']
BDD = BDD[~BDD['Departamento defunción'].isin(dep_elim)]

#Como la columna "Municipio defunción" tampoco tiene datos nulos, verificamos también sus categorías
sorted(BDD['Municipio defunción'].unique())
#se observa que pueden combinarse las categorías "CALIMA' y 'CALIMA (DARIEN)'


#Se combinan las categorías "CALIMA' y 'CALIMA (DARIEN)'
BDD['Municipio defunción'] = BDD['Municipio defunción'].replace({'CALIMA (DARIEN)': 'CALIMA'})

#Verificamos
sorted(BDD['Municipio defunción'].unique())

#Columna "Área defunción" tiene 3 datos nulos, los llenamos con el texto "SIN INFORMACIÓN" y verificamos también sus categorías
#Agregamos información a celdas vacías
BDD['Área defunción'].fillna('SIN INFORMACIÓN', inplace=True)
#Verificamos categorías
sorted(BDD['Área defunción'].unique())

#Unificamos las categorías: "CENTRO POBLADO (Inspección,\r\ncorregimiento o caserío)" y 'CENTRO POBLADO (INSPECCIÓN, CORREGIMIENTO O CASERÍO)' como "CENTRO POBLADO"
BDD['Área defunción'] = BDD['Área defunción'].replace({'"CENTRO POBLADO (Inspección,\r\ncorregimiento o caserío)"': 'CENTRO POBLADO', 'CENTRO POBLADO (INSPECCIÓN, CORREGIMIENTO O CASERÍO)':'CENTRO POBLADO'})
#Verificamos ajustes
sorted(BDD['Área defunción'].unique())

#Columna "Sitio defunción" no tiene datos nulos, verificamos categorías
sorted(BDD['Sitio defunción'].unique())
#No hay ajustes para esta variable

#Columna "Otro sitio de defunción" tiene 5254 nulos. Esta columna existe solo como complemento para la categoría "OTRO" de la variable "Sitio defunción",
#Por lo tanto, se reemplazará los datos nulos con el texto "NA" (no aplica), para las filas del resto de las categorías diferentes a "OTRO" que aparecen como nulos

#Agregamos información en celdas vacías
BDD['Otro sitio de defunción'].fillna('NA', inplace=True)

#Verificamos categorías
sorted(BDD['Otro sitio de defunción'].unique())

#Ponemos todas las categorías en mayúsculas, ya que solo "domicilio" está en minúscula.
BDD['Otro sitio de defunción'] = BDD['Otro sitio de defunción'].str.upper()
#Unificamos las categorías 'PRISIÓN REFORMATORIOS'y 'PRISIÓNREFORMATORIOS'
BDD['Otro sitio de defunción'] = BDD['Otro sitio de defunción'].replace({'PRISIÓNREFORMATORIOS': 'PRISIÓN REFORMATORIOS'})

#Verificamos nuevamente categorías
sorted(BDD['Otro sitio de defunción'].unique())

#Verificamos datos nulos
BDD['Otro sitio de defunción'].isnull().sum()

#Verificamos categorías de 'Nombre institución' de defunción que no tiene datos nulos
sorted(BDD['Nombre institución de defunción'].unique())
#Sin novedades en esta columna

#Verificamos categorías de 'Tipo de defunción' de defunción que no tiene datos nulos
sorted(BDD['Tipo de defunción'].unique())
#Sin novedades en esta columna

#La variable 'Fecha de Defunción' no tiene datos nulos, pero se ajusta el formato
# Convertir a formato de fecha
BDD['Fecha de Defunción'] = pd.to_datetime(BDD['Fecha de Defunción'])
#Verificamos
BDD.info('Fecha de Defunción')

#Como la columna "Hora de defunción" tiene 1072 datos vacíos, pero la columna anterior de fecha, contiene también la hora y no tenía datos nulos, se elimina la columna de hora para no considerarla.
BDD = BDD.drop('Hora de defunción', axis=1)

#Verificamos categorías de la columna sexo que no tiene datos nulos.
sorted(BDD['Sexo'].unique())
#Sin novedades en esta columna

#Agregamos la información a los datos vacíos de la columna "Estado civil" que tiene 51 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Estado civil'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna 'Estado civil'
sorted(BDD['Estado civil'].unique())

#Vamos a unificar algunas categorías
BDD['Estado civil'] = BDD['Estado civil'].replace({'ESTABA CASADO(A)': 'CASADO(A)',
                                                   'NO CASADO(A) Y DOS AÑOS O MAS CON SU PAREJA':'UNIÓN LIBRE',
                                                   'NO CASADO(A) Y MENOS DE DOS AÑOS CON SU PAREJA':'UNIÓN LIBRE',
                                                   'NO ESTABA CASADO(A) Y LLEVABA DOS AÑOS O MÁS VIVIENDO CON SU PAREJA':'UNIÓN LIBRE',
                                                   'NO ESTABA CASADO(A) Y LLEVABA MENOS DE DOS AÑOS VIVIENDO CON SU PAREJA':'UNIÓN LIBRE',
                                                   'ESTABA SEPARADO(A), DIVORCIADO(A)':'SEPARADO (A)',
                                                   'SEPARADO(A), DIVORCIADO(A)':'SEPARADO (A)',
                                                   'ESTABA SOLTERO(A)':'SOLTERO(A)',
                                                   'ESTABA VIUDO(A)':'VIUDO(A)'})

#Verificamos ajustes
sorted(BDD['Estado civil'].unique())

#Como la edad es una variable que podría tener gran significancia en esta base de datos, tener datos vacíos no sería útil y llenarlos con la media podría sesgar la información.
#Considerando que el conjunto de datos es de buenas dimensiones, se decide eliminar las filas con valores nulos en esta variable.
BDD = BDD.dropna(subset=['Edad'])

#Verificamos datos nulos
BDD['Edad'].isnull().sum()

#Ahora verificamos que los datos sean coherentes en cuanto a la edad
sorted(BDD['Edad'].unique())

#Como hay valores demasiado altos y esta podría ser una variable significativa, se eliminan las filas cuyos valores son mayores a 110 años.
#Convertimos la columna a tipo enteros
BDD['Edad'] = BDD['Edad'].astype(int)

#Eliminamos los valores mayores a 110
BDD = BDD[BDD['Edad'] <= 110]

#Verificamos nuevamente
sorted(BDD['Edad'].unique())

#Agregamos la información a los datos vacíos de la columna "Nivel educativo " que tiene 24 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Nivel educativo'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna 'Nivel educativo '
sorted(BDD['Nivel educativo'].unique())

#Vamos a unificar algunas categorías
BDD['Nivel educativo'] = BDD['Nivel educativo'].replace({'BASICA PRIMARIA': 'BÁSICA PRIMARIA',
                                                   'BASICA SECUNDARIA':'BÁSICA SECUNDARIA',
                                                   'MAESTRIA':'MAESTRÍA',
                                                   'MEDIA ACADEMICA O CLASICA':'MEDIA ACADÉMICA',
                                                   'MEDIA ACADÉMICA O CLÁSICA':'MEDIA ACADÉMICA',
                                                   'MEDIA TECNICA':'MEDIA TÉCNICA',
                                                   'TECNICA PROFESIONAL':'TÉCNICA PROFESIONAL',
                                                   'TECNOLOGICA':'TECNOLÓGICA',
                                                   'NORMALISTA':'MEDIA TÉCNICA'})

#Verificamos ajustes
sorted(BDD['Nivel educativo'].unique())

#Como la columna "Último curso fallecido" tiene 1141 datos vacíos, pero la columna anterior de "Nivel educativo", contiene información similar, se elimina esta columna de la base
BDD = BDD.drop('Último curso fallecido', axis=1)

#Agregamos la información a los datos vacíos de la columna "Ocupación" que tiene 205 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Ocupación'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna 'Ocupación'
sorted(BDD['Ocupación'].unique())

#Como son tantas categorías en esta variable, vamos a clasificar las categorías de "Ocupación" en una nueva columna de nombre "OCUPACION", tomando la parte general del oficio
#Renombramos la columna general
BDD.columns = BDD.columns.str.replace('Ocupación', 'Ocupación específica')

#Creamos la nueva columna
BDD['OCUPACION'] = BDD['Ocupación específica']

#Clasificamos las categorías agrupándolas así:

A= ['AGENTES COMERCIALES Y CORREDORES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'AGENTES DE COMPRAS, INTERMEDIARIOS Y CONSIGNATARIOS',
 'AGENTES DE LA ADMINISTRACIÓN PÚBLICA EN ADUANAS, IMPUESTOS Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'AGENTES DE LA POLICIA NACIONAL',
 'AGENTES Y POLICIAS DE TRANSITO']

B= 'AGENTES'

C= ['TÉCNICOS EN AGRONOMÍA, ZOOTECNIA Y SILVICULTURA',
 'TÉCNICOS EN DISEÑO Y DECORADORES',
 'TÉCNICOS TERAPEUTAS, QUIROPRÁCTICOS Y AFINES',
 'TÉCNICOS Y ASISTENTES EN FARMACIA',
 'TÉCNICOS Y ASISTENTES VETERINARIOS',
 'TÉCNICOS Y POSTSECUNDARIOS NO UNIVERSITARIOS EN CIENCIAS FÍSICAS, QUÍMICAS E INGENIERÍAS, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'TÉCNICOS, POSTSECUNDARIOS NO UNIVERSITARIOS EN INGENIERÍA CIVIL, ARQUITECTURA, AGRIMENSORES Y AFINES',
 'TÉCNICOS, POSTSECUNDARIOS NO UNIVERSITARIOS Y ASISTENTES DE SERVICIOS ADMINISTRATIVOS Y AFINES',
 'TÉCNICOS, POSTSECUNDARIOS NO UNIVERSITARIOS Y ASISTENTES EN OPERACIONES COMERCIALES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'T╔CNICOS E HIGIENISTAS DENTALES',
 'T╔CNICOS EN AGRONOM═A, ZOOTECNIA Y SILVICULTURA',
 'T╔CNICOS Y ASISTENTES EN FARMACIA']

D= 'TÉCNICOS'

E= ['OPERADORES DE EQUIPOS ÓPTICOS Y ELECTRÓNICOS, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'OPERADORES DE INSTALACIONES DE TRATAMIENTO DE AGUA Y AFINES',
 'OPERADORES DE MEZCLADORAS Y DE HORNOS DE VIDRIER═A Y AFINES',
 'OPERADORES DE MÁQUINAS PARA PROCESAR CARNE, PESCADO Y MARISCOS',
 'OPERADORES DE TELARES Y OTRAS MÁQUINAS TEJEDORAS',
 'OPERARIOS DE LA CONSERVACIÓN DE FRUTAS, LEGUMBRES, VERDURAS Y AFINES',
 'OPERARIOS DE LA FOTOGRAFÍA Y AFINES',
 'OPERARIOS DEL TRATAMIENTO DE LA MADERA',
 'OPERARIOS EN CEMENTO ARMADO, ENFOSCADORES Y AFINES',
 'OBREROS DE CARGA',
 'OBREROS DE LA CONSTRUCCIÓN DE EDIFICIOS',
 'OBREROS DE PESCA, CAZA Y TRAMPA',
 'OBREROS FORESTALES',
 'OBREROS Y PEONES AGROPECUARIOS DE LABRANZA Y DE INVERNADERO']

F='OPERARIOS'

G=['PROFESORES DE EDUCACIËN PRIMARIA',
 'PROFESORES DE EDUCACIËN SECUNDARIA',
 'PROFESORES DE EDUCACIÓN PRIMARIA',
 'PROFESORES DE EDUCACIÓN SECUNDARIA',
 'PROFESORES DE UNIVERSIDADES Y OTROS ESTABLECIMIENTOS DE EDUCACIËN SUPERIOR',
 'PROFESORES DE UNIVERSIDADES Y OTROS ESTABLECIMIENTOS DE EDUCACIÓN SUPERIOR',
 'PROFESORES E INSTRUCTORES DE EDUCACIËN ESPECIAL',
 'PROFESORES E INSTRUCTORES DE EDUCACIÓN ESPECIAL', 'PROFESIONALES DE LA EDUCACIËN, NO CLASIFICADOS BAJO OTROS EP═GRAFES',
 'PROFESIONALES DE LA EDUCACIÓN, NO CLASIFICADOS BAJO OTROS EPÍGRAFES']

H= 'PROFESORES'

I= [ 'VENDEDORES A DOMICILIO Y POR TELÉFONO',
 'VENDEDORES AMBULANTES',
 'VENDEDORES EN QUIOSCOS Y PUESTOS DE MERCADO',
 'VENDEDORES, DEMOSTRADORES DE TIENDAS Y ALMACENES']

J= 'VENDEDORES'

K=[ 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIËN Y OPERACIONES EN COMERCIO MAYORISTA Y MINORISTAS',
 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIÓN Y OPERACIONES EN AGRICULTURA, CAZA, SILVICULTURA Y PESCA',
 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIÓN Y OPERACIONES EN COMERCIO MAYORISTA Y MINORISTAS',
 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIÓN Y OPERACIONES EN CONSTRUCCIÓN Y OBRAS PÚBLICAS',
 'DIRECTORES DE DEPARTAMENTOS DE PRODUCCIÓN Y OPERACIONES EN INDUSTRIAS MANUFACTURERAS Y EXTRACTIVAS',
 'DIRECTORES GENERALES, DE EMPRESAS O ENTIDADES DE LA ADMINISTRACIËN P┌BLICA',
 'DIRECTORES Y GERENTES GENERALES DE EMPRESAS PRIVADAS',
 'DIRIGENTES Y ADMINISTRADORES DE ORGANIZACIONES DE EMPLEADORES, DE TRABAJADORES Y DE OTRAS DE INTERÉS SOCIOECONÓMICO']

L= 'DIRECTORES'

M= [ 'MECÁNICOS Y AJUSTADORES DE MÁQUINAS AGRÍCOLAS E INDUSTRIALES',
 'MECÁNICOS Y AJUSTADORES DE VEHÍCULOS DE MOTOR',
 'MECÁNICOS Y REPARADORES DE INSTRUMENTOS DE PRECISIÓN',
 'MEC┴NICOS Y AJUSTADORES DE VEH═CULOS DE MOTOR']

N= 'MECÁNICOS'

O= ['INGENIEROS CIVILES, INGENIEROS DE TRANSPORTE Y AFINES',
 'INGENIEROS ELÉCTRICOS, INGENIEROS ELECTRÓNICOS DE TELECOMUNICACIONES Y AFINES',
 'INGENIEROS INDUSTRIALES Y AFINES',
 'INGENIEROS MEC┴NICOS','AYUDANTE DE TALLER, MECÁNICA, VEHÍCULOS DE MOTOR Y AFINES']

P= 'INGENIEROS'

Q=['COORDINADORES Y SUPERVISORES DE ALMACENAMIENTO, ABASTECIMIENTO Y DISTRIBUCIÓN',
 'COORDINADORES Y SUPERVISORES DE PRODUCCIËN Y OPERACIONES EN CUIDADOS PERSONALES, LIMPIEZA Y SERVICIOS SIMILARES',
 'COORDINADORES Y SUPERVISORES DE PRODUCCIÓN Y OPERACIONES EN CUIDADOS PERSONALES, LIMPIEZA Y SERVICIOS SIMILARES',
 'COORDINADORES Y SUPERVISORES DE VENTAS Y COMERCIALIZACIÓN',
 'COORDINADORES Y SUPERVISORES EN MANDOS MEDIOS DE PRODUCCIÓN Y OPERACIONES EN EMPRESAS PÚBLICAS Y PRIVADAS, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'COORDINADORES Y SUPERVISORES FINANCIEROS Y ADMINISTRATIVOS',
 'OTROS COORDINADORES Y SUPERVISORES EN MANDOS MEDIOS DE EMPRESAS PÚBLICAS Y PRIVADAS, NO CLASIFICADAS BAJO OTROS EPÍGRAFES']

R= 'COORDINADORES'

S= ['CONDUCTORES DE BUSES, MICROBUSES Y COLECTIVOS',
 'CONDUCTORES DE CAMIONES Y VEHÍCULOS PESADOS',
 'CONDUCTORES DE CAMIONETAS Y VEHÍCULOS LIVIANOS',
 'CONDUCTORES DE TAXIS',
 'CONDUCTORES DE VEHÍCULOS ACCIONADOS A PEDAL O A BRAZO',
 'CONDUCTORES DE VEH═CULOS DE TRACCIËN ANIMAL']

T= 'CONDUCTORES'

U= [ 'AUXILIARES ADMINISTRATIVOS Y AFINES',
 'AUXILIARES DE ENFERMERÍA Y ODONTOLOGÍA',
 'AUXILIARES DE LA POLICIA NACIONAL',
'ASISTENTES DE COMERCIO EXTERIOR',
 'ASISTENTES DE ENSEÑANZA EN EDUCACIÓN PREESCOLAR', 'SECRETARIOS (AS)']

V= 'AUXILIARES - ASISTENTES'

W= ['MÉDICOS',
 'MÉDICOS VETERINARIOS Y ZOOTECNISTAS',
 'MÉDICOS, PROFESIONALES EN CIENCIAS DE LA SALUD Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
'ENFERMEROS(AS) PROFESIONALES']

X= 'MÉDICOS'

Y= ['AGRICULTORES DE CULTIVOS PERMANENTES (PLANTACIONES DE ÁRBOLES Y ARBUSTOS)',
 'AGRICULTORES DE CULTIVOS TRANSITORIOS','CRIADORES DE GANADO Y TRABAJADORES DE LA CR═A DE ANIMALES DOM╔STICOS DIVERSOS',
 'TRABAJADORES AGROPECUARIOS',
 'TRABAJADORES DE HUERTAS, INVERNADEROS, VIVEROS Y JARDINES',
 'TRABAJADORES PECUARIOS, GANADEROS Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'TRABAJADORES PECUARIOS, GANADEROS Y AFINES, NO CLASIFICADOS BAJO OTROS EP═GRAFES',]

Z= 'TRABAJOS EN EL CAMPO'

OTRO = ['ABOGADOS',  'ACOMPAÑANTES',
 'ACTIVIDADES NO ESPECIFICADAS',
 'ALBAÑILES, MAMPOSTEROS Y AFINES',
 'ALFAREROS Y AFINES (BARRO, ARCILLA Y ABRASIVOS)',
 'ANALISTAS DE SISTEMAS INFORMÁTICOS',
 'ARQUITECTOS Y URBANISTAS',
 'ARTESANOS DE LA MADERA Y MATERIALES SIMILARES',
 'ASEADORES Y FUMIGADORES DE OFICINAS, HOTELES Y OTROS ESTABLECIMIENTOS',
 'ATLETAS, DEPORTISTAS Y AFINES',
 'BOMBEROS Y RESCATISTAS',
 'BORDADORES Y AFINES',
 'CAJEROS Y EXPENDEDORES DE BILLETES',
 'CARNICEROS, PESCADEROS Y AFINES',
 'CARPINTEROS DE ARMAR Y DE BLANCO',
 'CATADORES Y CLASIFICADORES DE ALIMENTOS Y BEBIDAS',
 'COCINEROS Y AFINES',
 'COMPOSITORES, M┌SICOS Y CANTANTES',
 'COMPRADORES',
 'CONTADORES',
 'DESCANSAR, DORMIR, COMER O PARTICIPAR EN OTRAS ACTIVIDADES VITALES',
 'EBANISTAS Y AFINES',
 'ELECTRICISTAS DE OBRAS Y AFINES',
 'ELECTROTÉCNICOS',
 'ELECTROT╔CNICOS',
 'EMBALADORES MANUALES Y OTROS OBREROS DE LA INDUSTRIA MANUFACTURERA',
 'ENCARGADOS DE SERVICIOS DE TRANSPORTE',
 'ENSAMBLADORES DE MECANISMOS Y ELEMENTOS MECÁNICOS DE MÁQUINAS',
 'ESCRITORES, PERIODISTAS Y AFINES',
 'ESCULTORES, PINTORES Y AFINES',
 'ESPECIALISTAS EN ORGANIZACIÓN, ADMINISTRACIÓN DE EMPRESAS, ANÁLISIS FINANCIERO Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'ESTUDIANTE',
 'FONOAUDÍOLOGOS, FISIOTERAPEUTAS Y AFINES',
 'GUARDIANES DE PRISIÓN',
 'HERREROS Y FORJADORES',
 'HOGAR',
 'INSTALADORES Y REPARADORES DE TELÉGRAFOS, TELÉFONOS Y LÍNEAS ELECTRICAS',
 'JOYEROS, ORFEBRES Y PLATEROS',
 'LIMPIABOTAS Y OTROS TRABAJADORES CALLEJEROS',
 'MARINEROS DE CUBIERTA Y AFINES',
 'MENSAJEROS, PORTEADORES Y REPARTIDORES',
 'MESEROS, TABERNEROS Y AFINES',
 'NIÑERAS Y CUIDADORAS INFANTILES',
 'OCIO',
 'OFICIALES DE LA POLICÍA NACIONAL',
 'OFICIALES DE LAS FMS001',
 'OFICIALES Y OPERARIOS DE LA CONSTRUCCIÓN Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'OTRAS ACTIVIDADES ESPECÍFICAS',
 'OTRO TRABAJO',
 'OTROS ARTESANOS, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'OTROS TRABAJADORES DE SERVICIOS PERSONALES A PARTICULARES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'OTROS TRABAJADORES DE SERVICIOS PERSONALES A PARTICULARES, NO CLASIFICADOS BAJO OTROS EP═GRAFES',
 'PANADEROS, PASTELEROS Y CONFITEROS',
 'PELUQUEROS, ESPECIALISTAS EN TRATAMIENTOS DE BELLEZA Y AFINES',
 'PENSIONADO',
 'PERSONAL DE LOS SERVICIOS DE PROTECCIËN Y SEGURIDAD, NO CLASIFICADO BAJO OTROS EP═GRAFES',
 'PERSONAL DE LOS SERVICIOS DE PROTECCIÓN Y SEGURIDAD, NO CLASIFICADO BAJO OTROS EPÍGRAFES',
 'PESCADORES',
 'PINTORES DECORADORES DE VIDRIO, CERÁMICA Y OTROS MATERIALES',
 'PINTORES, BARNIZADORES Y ENLACADORES DE ARTÍCULOS METÁLICOS Y AFINES',
 'PINTORES, BARNIZADORES Y ENLACADORES DE ART═CULOS MET┴LICOS Y AFINES',
 'PINTORES, EMPAPELADORES Y AFINES',
 'PROFESIONALES DEL DERECHO, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'PROFESIONALES DEL DERECHO, NO CLASIFICADOS BAJO OTROS EP═GRAFES',
 'PSICÓLOGOS',
 'RECOLECTORES DE MATERIAL RECICLABLE',
 'REPRESENTANTES COMERCIALES Y TÉCNICOS DE VENTAS',
 'REVISORES, GUARDAS Y COBRADORES DE LOS SERVICIOS DE TRANSPORTE',
 'SACERDOTES Y RELIGIOSOS DE DISTINTAS DOCTRINAS',
 'SASTRES, MODISTOS COSTUREROS SOMBREREROS Y AFINES',
 'SOLDADORES Y OXICORTADORES',
 'TRABAJADORES DE LOS CUIDADOS PERSONALES Y AFINES, NO CLASIFICADOS BAJO OTROS EPÍGRAFES',
 'TRABAJADORES DE LOS CUIDADOS PERSONALES Y AFINES, NO CLASIFICADOS BAJO OTROS EP═GRAFES',
 'TRABAJADORES SOCIALES Y AFINES',
 'TRABAJO PARA OBTENER INGRESOS',
 'VIGILANTES Y CELADORES',
 'ZAPATEROS Y AFINES']

OTRAS = 'OTRAS OCUPACIONES ESPECÍFICAS'

#Ahora generamos las nuevas categorías
BDD['OCUPACION'] = BDD['OCUPACION'].replace(A,B)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(C,D)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(E,F)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(G,H)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(I,J)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(K,L)                                                 
BDD['OCUPACION'] = BDD['OCUPACION'].replace(M,N) 
BDD['OCUPACION'] = BDD['OCUPACION'].replace(O,P) 
BDD['OCUPACION'] = BDD['OCUPACION'].replace(Q,R) 
BDD['OCUPACION'] = BDD['OCUPACION'].replace(S,T) 
BDD['OCUPACION'] = BDD['OCUPACION'].replace(U,V) 
BDD['OCUPACION'] = BDD['OCUPACION'].replace(W,X)                                             
BDD['OCUPACION'] = BDD['OCUPACION'].replace(Y,Z)
BDD['OCUPACION'] = BDD['OCUPACION'].replace(OTRO,OTRAS)
BDD['OCUPACION'] = BDD['OCUPACION'].replace({'SIN INFORMACION':'SIN INFORMACIÓN'})                                                  

#Verificamos ajustes
sorted(BDD['OCUPACION'].unique())

#Agregamos la información a los datos vacíos de la columna "Cultura, pueblo, rasgos físicos" que tiene 22 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Cultura, pueblo, rasgos físicos'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Cultura, pueblo, rasgos físicos'].unique())

#Vamos a unificar algunas categorías
BDD['Cultura, pueblo, rasgos físicos'] = BDD['Cultura, pueblo, rasgos físicos'].replace({'NEGRO(A), MULATO(A), AFRO COLOMBIANO(A) O AFRO DESCENDIENTE': 'NEGRO(A), MULATO(A), AFROCOLOMBIANO(A) O AFRODESCENDIENTE',
                                                   'NINGUNA DE LAS ANTERIORES':'NINGUNA',
                                                   'NINGUNO DE LOS ANTERIORES':'NINGUNA'})

#Verificamos ajustes
sorted(BDD['Cultura, pueblo, rasgos físicos'].unique())

#Como los datos son aplicados a Colombia y las variables "País de residencia", "Departamento de residencia" y "Municipio de residencia" tienen 2 datos nulos cada una, se procede a eliminar estas dos filas para cada una.
BDD = BDD.dropna(subset=['País de residencia', 'Departamento de residencia', 'Municipio de residencia'])

#Verificamos datos nulos
BDD.isnull().sum()

#Agregamos la información a los datos vacíos de la columna "Area de residencia" que tiene 2 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Area de residencia'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Area de residencia'].unique())

#Vamos a unificar algunas categorías
BDD['Area de residencia'] = BDD['Area de residencia'].replace({'"CENTRO POBLADO (Inspección,\r\ncorregimiento o caserío)"':'CENTRO POBLADO (INSPECCIÓN, CORREGIMIENTO O CASERÍO)'})

#Verificamos ajustes
sorted(BDD['Area de residencia'].unique())

#Agregamos la información a los datos vacíos de la columna "Barrio de fallecido" que tiene 210 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Barrio de fallecido'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Barrio de fallecido'].unique())

#Vamos a unificar algunas categorías
BDD['Barrio de fallecido'] = BDD['Barrio de fallecido'].replace({'ACUARELA':'ACUARELAS',
                                                                 'ALTO BONITO':'ALTOBONITO',
                                                                 'ALTOS DE GUADALAJARA':'ALTOS DEL GUADALAJARA',
                                                                 'BALCONESL DEL NORTE':'BALCONES DEL NORTE',
                                                                 'BELLAVISTA':'BELLA VISTA',
                                                                 'DIVINNO NIÑO':'DIVINO NIÑO',
                                                                 'DIVINO NINO':'DIVINO NIÑO',
                                                                 'EL DIVINO NIÑO':'DIVINO NIÑO',
                                                                 'ENTRE VALLES':'ENTREVALLES',
                                                                 'FUENMAYOR': 'FUEN MAYOR',
                                                                 'GONZALO ECHEVERRI':'GONZALO ECHEVERRY',
                                                                 'JORGE ELIZER GAITAN':'JORGE ELIECER GAITAN',
                                                                 'LA CONFORNIA':'LA CONCORDIA',
                                                                 'LA CORCORDIA':'LA CONCORDIA',
                                                                 'LA MARCED':'LA MERCED',
                                                                 'LAS MERCED': 'LA MERCED',
                                                                 'LA REVOLUCION':'LA REVOLUCIÓN',
                                                                 'LA REVOLUSION':'LA REVOLUCIÓN',
                                                                 'REVOLUCION':'LA REVOLUCIÓN',
                                                                 'MARA LUISA DE LA ESPADA': 'MARIA LUISA  LA ESPADA',
                                                                 'MARIA LUISA': 'MARIA LUISA DE LA ESPADA',
                                                                 'MARIA LUISA  LA ESPADA':'MARIA LUISA DE LA ESPADA',
                                                                 'MARIA LUISA LA EPSADA':'MARIA LUISA DE LA ESPADA',
                                                                 'MARIA LUISA LA ESPADA':'MARIA LUISA DE LA ESPADA',
                                                                 'MARIA LUISA  LA ESPADA':'MARIA LUISA DE LA ESPADA',
                                                                 'NO RECUERDA':'NO IDENTIFICADO',
                                                                 'NO SABE':'NO IDENTIFICADO',
                                                                 'OTROS':'OTRO',
                                                                 'OTROS BARRIOS':'OTRO',
                                                                 'SD':'OTRO',
                                                                 'RICAUTE':'RICAURTE',
                                                                 'SAN JOSE DE LAS PALMAS':'SAN JOSÉ DE LAS PALMAS',
                                                                 'SIN DATOS': 'SIN INFORMACIÓN',
                                                                 'SIN INFORMACION':'SIN INFORMACIÓN',
                                                                 'UNI NORTE': 'UNINORTE'})

#Verificamos ajustes
sorted(BDD['Barrio de fallecido'].unique())

#Verificamos categorías de la columna "Vereda del fallecido" que no tiene datos nulos
sorted(BDD['Vereda del fallecido'].unique())

#Vamos a unificar algunas categorías
BDD['Vereda del fallecido'] = BDD['Vereda del fallecido'].replace({'CHAMBINBAL':'CHAMBIMBAL',
                                                                    'CHAMBINBAL SAN ANTONIO':'CHAMBIMBAL SAN ANTONIO',
                                                                    'MEDIACANOA':'MEDIA CANOA',
                                                                    'MIRAVLLE':'MIRAVALLE',
                                                                    'NO DIENTIFICADA':'NO IDENTIFICADA',
                                                                    'SIN INFORMACION':'SIN INFORMACIÓN',
                                                                    'chambimbal la campiña':'CHAMBIMBAL LA CAMPIÑA',
                                                                   'el manantial':'EL MANANTIAL',
                                                                   'el vinculo':'EL VINCULO'})
#Verificamos ajustes
sorted(BDD['Vereda del fallecido'].unique())

#Agregamos la información a los datos vacíos de la columna "Seguridad social" que tiene 27 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Seguridad social'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Seguridad social'].unique())
#No hay más ajustes para esta columna

#Verificamos categorías de la columna "Entidad administradora de salud" que no tiene datos nulos
sorted(BDD['Entidad administradora de salud'].unique())

#Vamos a unificar algunas categorías
BDD['Entidad administradora de salud'] = BDD['Entidad administradora de salud'].replace({'ASMET SALUD EPS SAS -CM':'ASMET SALUD EPS SAS',
                                                                                         'ASMET SALUD ESS - ASOCIACION MUTUAL LA ESPERANZA':'ASMET SALUD EPS SAS',
                                                                                         'ASOCIACIÓN MUTUAL LA ESPERANZA - ASMET SALUD':'ASMET SALUD EPS SAS',
                                                                                         'ASOCIACIÓN MUTUAL LA ESPERANZA - ASMET SALUD -CM':'ASMET SALUD EPS SAS',
                                                                                         'ASOCIACIÓN MUTUAL LA ESPERANZA ASMET  SALUD-CM':'ASMET SALUD EPS SAS',
                                                                                         'ASOCIACIÓN MUTUAL EMPRESA SOLIDARIA DE SALUD DE NARIÑO - EMSSANAR E.S.S. -CM':'ASOCIACIÓN MUTUAL EMPRESA SOLIDARIA DE SALUD DE NARIÑO - EMSSANAR E.S.S.',
                                                                                         'ASOCIACIÓN MUTUAL EMPRESA SOLIDARIA DE SALUD DE NARIÑO E.S.S. EMSSANAR E.S.S.-CM':'ASOCIACIÓN MUTUAL EMPRESA SOLIDARIA DE SALUD DE NARIÑO - EMSSANAR E.S.S.',
                                                                                         'CAFESALUD E.P.S.':'CAFESALUD E.P.S.  S.A.',
                                                                                         'COMFENALCO VALLE':'COMFENALCO  VALLE  E.P.S.',
                                                                                         'COMPENSAR   E.P.S.-CM':'COMPENSAR   E.P.S.',
                                                                                         'COMPENSAR E.P.S.':'COMPENSAR   E.P.S.',
                                                                                         'COMPENSAR E.P.S. -CM':'COMPENSAR   E.P.S.',
                                                                                         'COOMEVA   E.P.S.  S.A.':'COOMEVA E.P.S. S.A.',
                                                                                         'COOMEVA E.P.S. S.A. -CM':'COOMEVA E.P.S. S.A.',
                                                                                         'COOMEVA MEDICINA PREPAGADA S.A.':'COOMEVA E.P.S. S.A.',
                                                                                         'COOPERATIVA DE SALUD Y DESARROLLO INTEGRAL ZONA SUR ORIENTAL DE CARTAGENA LTDA. - COOSALUD E.S.S. -CM':'COOPERATIVA DE SALUD Y DESARROLLO INTEGRAL ZONA SUR ORIENTAL DE CARTAGENA LTDA. - COOSALUD E.S.S.',
                                                                                         'E.P.S. SANITAS':'E.P.S.  SANITAS  S.A.',
                                                                                         'EPS SANITAS - CM':'E.P.S.  SANITAS  S.A.',
                                                                                         'EMSSANAR ESS - ASOCIACION MUTUAL EMPRESA SOLIDARIA DE SALUD':'EMSSANAR S.A.S.',
                                                                                         'ENTIDAD COOPERATIVA SOLIDARIA DE SALUD DEL NORTE DE SOACHA - ECOOPSOS -CM':'ENTIDAD COOPERATIVA SOLIDARIA DE SALUD DEL NORTE DE SOACHA - ECOOPSOS',
                                                                                         'EPS S.O.S. S.A. - EPS SERVICIO OCCIDENTAL DE SALUD  S.A.': 'EPS SERVICIO OCCIDENTAL DE SALUD  S.A. - EPS S.O.S. S.A.-CM',
                                                                                         'EPS Y MEDICINA PREPAGADA SURAMERICANA S.A': 'EPS SURA',
                                                                                         'EPS Y MEDICINA PREPAGADA SURAMERICANA S.A -CM': 'EPS SURA',
                                                                                         'EPS Y MEDICINA PREPAGADA SURAMERICANA S.A-CM': 'EPS SURA',
                                                                                         'EPS Y MEDICINA PREPAGADA SURAMERICANA S.A.': 'EPS SURA',
                                                                                         'FAMISANAR E.P.S. LTDA - CAFAM - COLSUBSIDIO -CM':'FAMISANAR E.P.S. LTDA - CAFAM - COLSUBSIDIO',
                                                                                         'MEDIMÁS EPS S.A.S. CONTRIBUTIVO':'MEDIMÁS EPS S.A.S.',
                                                                                         'MEDIMÁS EPS S.A.S. SUBSIDIADO':'MEDIMÁS EPS S.A.S.',
                                                                                         'MEDIMÁS EPS S.A.S. -CM':'MEDIMÁS EPS S.A.S.',
                                                                                         'LA NUEVA EPS S.A.-CM':'NUEVA EPS S.A',
                                                                                         'NUEVA EPS S.A.':'NUEVA EPS S.A',
                                                                                         'NUEVA EPS S.A. -CM':'NUEVA EPS S.A',
                                                                                         'NUEVA EPS SA':'NUEVA EPS S.A',
                                                                                         'SALUD TOTAL E.P.S. -CM':'SALUD TOTAL S.A.',
                                                                                         'SALUD TOTAL S.A. ENTIDAD PROMOTORA DE SALUD':'SALUD TOTAL S.A.',
                                                                                         'SAVIA SALUD E.P.S. -CM': 'SAVIA SALUD E.P.S.',
                                                                                         'SERVICIO OCCIDENTAL DE SALUD - S.O.S. S.A. -CM': 'SERVICIO OCCIDENTAL DE SALUD - S.O.S. S.A.'})
#Verificamos ajustes
sorted(BDD['Entidad administradora de salud'].unique())

#Agregamos la información a los datos vacíos de la columna "Probable manera de muerte" que tiene 640 datos nulos, con la anotación "SIN INFORMACIÓN"
BDD['Probable manera de muerte'].fillna('SIN INFORMACIÓN', inplace=True)

#Verificamos categorías de la columna
sorted(BDD['Probable manera de muerte'].unique())
#No hay más ajustes para esta columna

#Como las variables "longitud", "latitud" y localización pueden aportarnos información espacial visual de los datos, se conservan y se reemplazan los datos nulos con cero (894 datos nulos cada uno)
BDD['longitud'].fillna(0, inplace=True)
BDD['latitud'].fillna(0, inplace=True)
BDD['Geolocalización'].fillna('NA', inplace=True)

#Confirmamos el tipo object para la variable de geolocalización
BDD['Geolocalización'] = BDD['Geolocalización'].astype(object)

#Verificamos los datos nulos
BDD.isnull().sum()

#No quedan datos nulos en las variables, y para garantizar que la información de las variables "año" y "mes" sean correctas, se reemplaza la información de estas columnas a partir de la variable "Fecha de Defunción"
# Extraer el nombre del mes y agregarlo en la columna 'mes'
BDD['mes'] = BDD['Fecha de Defunción'].dt.strftime('%B')
# Extraer el año y agregarlo en columna 'año'
BDD['año'] = BDD['Fecha de Defunción'].dt.year

#Verificamos el contenido de las variables
BDD[['año', 'mes']]

#Hemos finalizado la limpieza y preprocesamiento de todas las variables en la base de datos.
#Verificamos las dimensiones finales del conjunto de datos


##EXPLORACIÓN Y ANÁLISIS DE LOS DATOS
#ahora haremos una exploración rapida de las variables
EXP= sv.analyze(BDD)
EXP.show_notebook()

# crear dataset para Cantidad de defunciones por Sexo y por año

BASE_A = BDD.groupby(['Sexo','año'])[['N°']].count().reset_index()

# crear gráfica
fig_A = px.bar(BASE_A, x = 'año', y ='N°', color ='Sexo', barmode = 'group')

# agregar detalles a la gráfica
fig_A.update_layout(
    title = '<b>Cantidad de defunciones por Sexo y por año<b>',
    xaxis_title = 'Año de defunción',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_A.show()

# crear dataset para Cantidad de defunciones por Municipio y por año

BASE_B = BDD.groupby(['Municipio defunción','año'])[['N°']].count().reset_index()

# crear gráfica
fig_B = px.bar(BASE_B, x = 'año', y ='N°', color ='Municipio defunción', barmode = 'group')

# agregar detalles a la gráfica
fig_B.update_layout(
    title = '<b>Cantidad de defunciones por Municipio y por año<b>',
    xaxis_title = 'Año de defunción',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_B.show()

#Observamos en el mapa, la distribución de muertes

#Importamos librería requerida
import folium

# Crea un mapa centrado en una ubicación inicial
mapa = folium.Map(location=[BDD['latitud'].mean(), BDD['longitud'].mean()], zoom_start=10)

for index, row in BDD.iterrows():
    folium.Marker([row['latitud'], row['longitud']]).add_to(mapa)
    
from IPython.display import IFrame
display(mapa)

# crear dataset para Cantidad de defunciones por la Probable manera de muerte y por año

BASE_C = BDD.groupby(['Probable manera de muerte','año'])[['N°']].count().reset_index()

# crear gráfica
fig_C = px.bar(BASE_C, x = 'año', y ='N°', color ='Probable manera de muerte', barmode = 'group')

# agregar detalles a la gráfica
fig_C.update_layout(
    title = '<b>Cantidad de defunciones por la Probable manera de muerte y por año<b>',
    xaxis_title = 'Año de defunción',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_C.show()


# crear dataset para Cantidad de defunciones por Edad y por año

BASE_D = BDD.groupby(['Edad','año'])[['N°']].count().reset_index()

# crear gráfica
fig_D = px.bar(BASE_D, x = 'año', y ='N°', color ='Edad', barmode = 'group')

# agregar detalles a la gráfica
fig_D.update_layout(
    title = '<b>Cantidad de defunciones por Edad y por año<b>',
    xaxis_title = 'Año de defunción',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_D.show()


# crear dataset para Cantidad de defunciones por Estado civil y por Nivel educativo

BASE_E = BDD.groupby(['Nivel educativo','Estado civil'])[['N°']].count().reset_index()

# crear gráfica
fig_E = px.bar(BASE_E, x = 'Estado civil', y ='N°', color ='Nivel educativo', barmode = 'group')

# agregar detalles a la gráfica
fig_E.update_layout(
    title = '<b>Cantidad de defunciones por Estado civil y por Nivel educativo<b>',
    xaxis_title = 'Estado civil',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_E.show()

# crear dataset para Cantidad de defunciones por mes y por Probable manera de muert

BASE_F = BDD.groupby(['mes','Probable manera de muerte'])[['N°']].count().reset_index()

# crear gráfica
fig_F = px.bar(BASE_F, x = 'Probable manera de muerte', y ='N°', color ='mes', barmode = 'group')

# agregar detalles a la gráfica
fig_F.update_layout(
    title = '<b>Cantidad de defunciones por mes y por Probable manera de muerte<b>',
    xaxis_title = 'Probable manera de muerte',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_F.show()

# crear dataset para Cantidad de defunciones porEdad y por Probable manera de muert

BASE_G = BDD.groupby(['Edad','Probable manera de muerte'])[['N°']].count().reset_index()

# crear gráfica
fig_G = px.bar(BASE_G, x = 'Probable manera de muerte', y ='N°', color ='Edad', barmode = 'group')

# agregar detalles a la gráfica
fig_G.update_layout(
    title = '<b>Cantidad de defunciones por Edad y por Probable manera de muerte<b>',
    xaxis_title = 'Probable manera de muerte',
    yaxis_title = 'Número de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_G.show()

#Veamos la Entidad administradora de salud para las defunciones cuya "probable manera de muerte" fue la "NATURAL (ENFERMEDAD)"
# crear dataset para MUERTE NATURAL

base_H = BDD[BDD['Probable manera de muerte'].isin(['NATURAL (ENFERMEDAD)'])]
base_H = base_H.groupby(['Probable manera de muerte','Entidad administradora de salud'])[['N°']].count().reset_index()

# crear gráfica
fig_H = px.bar(base_H, x='Entidad administradora de salud', y='N°', color ='Probable manera de muerte', barmode ='group', title ='<b>Entidad administradora de salud para las defunciones cuya "probable manera de muerte" fue la "NATURAL (ENFERMEDAD)"<b>')

# agregar detalles a la gráfica
fig_H.update_layout(
    xaxis_title = 'Entidad administradora de salud',
    yaxis_title = 'N° de defunciones',
    template = 'simple_white',
    title_x = 0.5)

fig_H.show()

###########DEJAMOS HASTA AQUÍ LA EXPLORACIÓN DE LOS DATOS###########
#Aplicación de Algoritmo K-means
#Creación de dataset
#Para poder continuar, debemos ajustar la base y sus variables, pasándolas a númericas

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Separar variables numéricas y categóricas (Esto es importante para poder aplicar diferentes transformaciones a cada tipo de variable)
numeric_features = ['Edad', 'longitud', 'latitud', 'año', 'N°']
categorical_features = ['Departamento defunción', 'Municipio defunción', 'Área defunción',
                        'Sitio defunción', 'Otro sitio de defunción', 'Nombre institución de defunción', 'Tipo de defunción',
                        'Fecha de Defunción', 'Sexo', 'Estado civil', 'Nivel educativo', 'Ocupación específica', 'Cultura, pueblo, rasgos físicos',
                        'País de residencia', 'Departamento de residencia', 'Municipio de residencia', 'Area de residencia', 'Barrio de fallecido',
                        'Vereda del fallecido', 'Seguridad social', 'Entidad administradora de salud', 'Probable manera de muerte',
                        'mes', 'Geolocalización', 'OCUPACION']

# Crear transformador de columnas (Para las variables numéricas, se aplica una estandarización ( StandardScaler), que escala las características de manera que tengan una media de 0 y una desviación estándar de 1.
#Para las variables categóricas, se aplica un codificador one-hot ( OneHotEncoder), que convierte las variables categóricas en una representación binaria.)

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(), categorical_features)])

# Crear un pipeline
pipeline = Pipeline(steps=[('preprocessor', preprocessor)])

# Aplicar el preprocesamiento a tus datos
X_processed = pipeline.fit_transform(BDD)
#El resultado ( X_processed) es la base de datos con las transformaciones aplicadas.

#Creación de clusters desde la base procesada

# Obtener el número de muestras y características (n_samples representa el número de muestras (filas), y n_features representa el número de características (columnas).)
n_samples, n_features = X_processed.shape

# Definir el número de centros (clusters)
centers = 3 ###ESTO PODEMOS CAMBIARLO

# Definir la desviación estándar (cluster_std)
cluster_std = 1.0 ###ESTO PODEMOS CAMBIARLO

# Generar el conjunto de datos sintético
synthetic_data, true_labels = make_blobs(n_samples=n_samples,
                                         n_features=n_features,
                                         centers=centers,
                                         cluster_std=cluster_std,
                                         random_state=42)


# Extraer las características de la base de datos en un arreglo NumPy
features = synthetic_data

#Mostrar las cinco primeras filas
features[:5]

#En resumen, se trata de una matriz dispersa de 5 filas y 1354 columnas con 150 elementos distintos de cero almacenados.

#Esto permite ver una muestra inicial de las etiquetas reales asociadas a las primeras muestras del conjunto de datos.
true_labels[:5]

##Preprocesamiento de los datos

from sklearn.preprocessing import StandardScaler
from scipy.sparse import csr_matrix

# Convertir a un formato compatible con scipy.sparse
X_sparse = csr_matrix(features)

# Crear un objeto StandardScaler para matrices dispersas
scaler = StandardScaler(with_mean=False) #no se centran las características en cero

# Aplicar el escalamiento
scaled_features = scaler.fit_transform(features)

#obtener las primeras cinco filas de un conjunto de datos que ha sido escalado. Esto mostrará una muestra de cómo se ven las primeras cinco muestras después de aplicar la escalada
scaled_features[:5]

Algoritmo K-means

# Creación de modelo de Kmeans
kmeans = KMeans(init="random",
                n_clusters=3,
                n_init=10,
                max_iter=100,
                random_state=42)

# Ajuste de algoritmo a caracteristicas escaladas
kmeans.fit(scaled_features)

# el valor del SSE mas bajo
print("valor del SSE mas bajo: ", kmeans.inertia_)

# Coordenadas de los centroides
print(kmeans.cluster_centers_)

# Numero de interaciones necesarias para converger
print("Numero de iteraciones: ",kmeans.n_iter_)

# Etiqueta de los datos generadas por Kmeans
kmeans.labels_[:5]

#Predecir valores de etiquetas
label = kmeans.fit_predict(scaled_features)

print(label)

#Obtener valores unicos de cluster   (AJUSTAR: Para solucionar este problema, asegúrese de que scaled_featuresy label estén
# definidos correctamente y que estén en un formato que pueda ser indexado de esta manera.)

u_labels = np.unique(label)

#Diagramar el resultado:
for i in u_labels:
    plt.scatter(scaled_features[label == i,0] , scaled_features[label == i,1] , label = i)
plt.legend()
plt.show()

Elección del número apropiado de clústeres

#Método del codo

# Argumentos del algoritmo
kmeans_kwargs = {"init": "random", "n_init": 10, "max_iter": 300, "random_state": 42}
# Lista que almacena los valores de SSE para cada valor K
sse = []
# Ciclo para entrenar algoritmos de kmeans con cada valor de k
for k in range(1, 11):
  kmeans = KMeans(n_clusters=k, **kmeans_kwargs)
  kmeans.fit(scaled_features)
  sse.append(kmeans.inertia_)

# Visualización de resultados
plt.style.use("fivethirtyeight")
plt.plot(range(1, 11), sse)
plt.xticks(range(1, 11))
plt.xlabel("Number of Clusters")
plt.ylabel("SSE")
plt.show()

# Seleccion automatica del numero k
kl = KneeLocator(range(1, 11),
                 sse, curve="convex",
                 direction="decreasing")

kl.elbow

#Coeficiente de silueta

# Lista contiene los coeficientes de silueta para cada k
silhouette_coefficients = []
# Fíjate que empiezas con 2 grupos para el coeficiente de silueta
for k in range(2, 11):
  kmeans = KMeans(n_clusters=k, **kmeans_kwargs)
  kmeans.fit(scaled_features)
  score = silhouette_score(scaled_features, kmeans.labels_)
  silhouette_coefficients.append(score)

# Visualización de resultados
plt.style.use("fivethirtyeight")
plt.plot(range(2, 11), silhouette_coefficients)
plt.xticks(range(2, 11))
plt.xlabel("Number of Clusters")
plt.ylabel("Silhouette Coefficient")
plt.show()





